{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d69efbb",
   "metadata": {},
   "source": [
    "# web crawler CNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "710afebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30188d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91f0d775",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define the seed URL of CNN's news section\n",
    "seed_url = 'https://edition.cnn.com/politics'\n",
    "\n",
    "# Initialize a list to store collected CNN news data\n",
    "cnn_news_data = []\n",
    "# Function to crawl CNN's news section and extract news articles\n",
    "def crawl_cnn_news(url):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        # Find all news article elements\n",
    "        articles = soup.find_all('div', class_='container_lead-plus-headlines__cards-wrapper')\n",
    "        for article in articles:\n",
    "            title = article.find('h2').text\n",
    "            content = article.find('p').text\n",
    "            date = article.find('span', class_='date').text\n",
    "            # Add extracted CNN news data to the cnn_news_data list\n",
    "            cnn_news_data.append({'title': title, 'content': content, 'date': date})\n",
    "        # Find next page link if available\n",
    "        next_page = soup.find('a', class_='next-page')\n",
    "        if next_page:\n",
    "            next_url = next_page['href']\n",
    "            crawl_cnn_news(next_url)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04966518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start crawling CNN's news section from the seed URL\n",
    "crawl_cnn_news(seed_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5852cb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Display collected CNN news data\n",
    "for news in cnn_news_data:\n",
    "    print(f\"Title: {news['title']}\")\n",
    "    print(f\"Content: {news['content']}\")\n",
    "    print(f\"Date: {news['date']}\")\n",
    "    print(\"-------------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3365555a",
   "metadata": {},
   "source": [
    "# twitter scrapping "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2991103f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 23.3.1\n",
      "  latest version: 23.7.2\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "Or to minimize the number of packages updated during conda update use\n",
      "\n",
      "     conda install conda=23.7.2\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conda install git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "89fd19b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/tweepy/tweepy.git\n",
      "  Cloning https://github.com/tweepy/tweepy.git to c:\\users\\eyawo\\appdata\\local\\temp\\pip-req-build-9vcnpa_l\n",
      "  Resolved https://github.com/tweepy/tweepy.git to commit c7471ffc85e9d924e9f804d045aef9c6e0e2f45c\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting oauthlib<4,>=3.2.0\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "     -------------------------------------- 151.7/151.7 kB 1.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: requests<3,>=2.27.0 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from tweepy==4.14.0) (2.28.1)\n",
      "Collecting requests-oauthlib<2,>=1.2.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from requests<3,>=2.27.0->tweepy==4.14.0) (2023.7.22)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from requests<3,>=2.27.0->tweepy==4.14.0) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from requests<3,>=2.27.0->tweepy==4.14.0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from requests<3,>=2.27.0->tweepy==4.14.0) (3.4)\n",
      "Building wheels for collected packages: tweepy\n",
      "  Building wheel for tweepy (setup.py): started\n",
      "  Building wheel for tweepy (setup.py): finished with status 'done'\n",
      "  Created wheel for tweepy: filename=tweepy-4.14.0-py3-none-any.whl size=99108 sha256=858ff81b7372e38cb6af852acd7dca1f9d0de216bddec0d17844cacfad76b890\n",
      "  Stored in directory: C:\\Users\\eyawo\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-g6jurvc8\\wheels\\dc\\75\\73\\ac2b7c1ac66d801a0b03c7707a2fc16e8689f792b585994c6f\n",
      "Successfully built tweepy\n",
      "Installing collected packages: oauthlib, requests-oauthlib, tweepy\n",
      "Successfully installed oauthlib-3.2.2 requests-oauthlib-1.3.1 tweepy-4.14.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/tweepy/tweepy.git 'C:\\Users\\eyawo\\AppData\\Local\\Temp\\pip-req-build-9vcnpa_l'\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/tweepy/tweepy.git\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "992f36df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status Failed On, 403 Forbidden\n",
      "453 - You currently have access to a subset of Twitter API v2 endpoints and limited v1.1 endpoints (e.g. media post, oauth) only. If you need access to this endpoint, you may need a different access level. You can learn more here: https://developer.twitter.com/en/portal/product\n"
     ]
    }
   ],
   "source": [
    "import tweepy\n",
    "\n",
    "# Your Twitter API keys\n",
    "consumer_key = \"F0iQh78LQ7i1XMD6hJ7uTOBew\"\n",
    "consumer_secret = \"u2Wn7BoxlXyWslv8amHCiiDLDlk51MEOydxw4FfUsBpMRSOBZ3\"\n",
    "access_token = \"1636765367451230209-HKRjedpRK34DEyc3U4Muw8dMjrrXTH\"\n",
    "access_token_secret = \"d9iCix5JoUeDtwV2dhMtNEw0mLIxl7PxfasydJzbrIE1l\"\n",
    "\n",
    "\n",
    "#Pass in our twitter API authentication key\n",
    "auth = tweepy.OAuth1UserHandler(\n",
    "    consumer_key, consumer_secret,\n",
    "    access_token, access_token_secret\n",
    ")\n",
    "\n",
    "#Instantiate the tweepy API\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True)\n",
    "\n",
    "\n",
    "search_query = \"Tunisia\"\n",
    "no_of_tweets =150\n",
    "\n",
    "\n",
    "try:\n",
    "    #The number of tweets we want to retrieved from the search\n",
    "    tweets = api.search_tweets(q=search_query, count=no_of_tweets)\n",
    "    \n",
    "    #Pulling Some attributes from the tweet\n",
    "    attributes_container = [[tweet.user.name, tweet.created_at, tweet.favorite_count, tweet.source,  tweet.text] for tweet in tweets]\n",
    "\n",
    "    #Creation of column list to rename the columns in the dataframe\n",
    "    columns = [\"User\", \"Date Created\", \"Number of Likes\", \"Source of Tweet\", \"Tweet\"]\n",
    "    \n",
    "    #Creation of Dataframe\n",
    "    tweets_df = pd.DataFrame(attributes_container, columns=columns)\n",
    "except BaseException as e:\n",
    "    print('Status Failed On,',str(e))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ad4287",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c5970eff",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'searched_tweets' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 35\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# Create DataFrame with consistent indentation\u001b[39;00m\n\u001b[0;32m     34\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(columns\u001b[38;5;241m=\u001b[39mCOLS)\n\u001b[1;32m---> 35\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m tweet \u001b[38;5;129;01min\u001b[39;00m \u001b[43msearched_tweets\u001b[49m:\n\u001b[0;32m     36\u001b[0m     df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtweet_id\u001b[39m\u001b[38;5;124m\"\u001b[39m : tweet\u001b[38;5;241m.\u001b[39mid_str,\n\u001b[0;32m     37\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtweet_created_at\u001b[39m\u001b[38;5;124m'\u001b[39m : tweet\u001b[38;5;241m.\u001b[39mcreated_at,\n\u001b[0;32m     38\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtweet_lang\u001b[39m\u001b[38;5;124m'\u001b[39m : tweet\u001b[38;5;241m.\u001b[39mlang,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     63\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoordinates\u001b[39m\u001b[38;5;124m'\u001b[39m : tweet\u001b[38;5;241m.\u001b[39mcoordinates,\n\u001b[0;32m     64\u001b[0m                     }, ignore_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "\u001b[1;31mNameError\u001b[0m: name 'searched_tweets' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import tweepy #tweepy (library to access twitter API)\n",
    "import json\n",
    "import numpy as np \n",
    "import time\n",
    "import pickle\n",
    "\n",
    "\n",
    "#below are the credentials obtained by requesting, to use twitter API. \n",
    "#get your own api keys @https://developer.twitter.com/en\n",
    "consumer_key = \"F0iQh78LQ7i1XMD6hJ7uTOBew\"\n",
    "consumer_secret = \"u2Wn7BoxlXyWslv8amHCiiDLDlk51MEOydxw4FfUsBpMRSOBZ3\"\n",
    "access_token = \"1636765367451230209-HKRjedpRK34DEyc3U4Muw8dMjrrXTH\"\n",
    "access_token_secret = \"d9iCix5JoUeDtwV2dhMtNEw0mLIxl7PxfasydJzbrIE1l\"\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "def user_tweets(screen_name):\n",
    "    all_tweets_info = tweepy.Cursor(api.user_timeline, screen_name=screen_name, tweet_mode='extended').items(200)\n",
    "    searched_tweets = [status for status in all_tweets_info]  # Define searched_tweets here\n",
    "\n",
    "\n",
    "COLS = [\"tweet_id\", 'tweet_created_at', 'tweet_lang', 'tweet_source', \"tweet_hashtags\", \"tweet_user_mentions_id\",\n",
    "        \"tweet_full_text\", \"user_id_str\", 'user_screen_name', 'user_name', \"user_profile_description\", \"user_statuses_count\",\n",
    "        'user_followers_count', \"user_friends_count\", \"user_listed_count\", \"user_verified\", \"user_time_zone\", \"geo_enabled\",\n",
    "        \"user_timeline_lang\", \"geo\", 'user_location', \"user_profile_created_at\", \"place_coordinates\", \"place_id\", \"place_type\",\n",
    "        \"place_country_code\", \"place_name\", \"coordinates\"\n",
    "        ]\n",
    "\n",
    "# Create DataFrame with consistent indentation\n",
    "df = pd.DataFrame(columns=COLS)\n",
    "for tweet in searched_tweets:\n",
    "    df = df.append({\"tweet_id\" : tweet.id_str,\n",
    "                    'tweet_created_at' : tweet.created_at,\n",
    "                    'tweet_lang' : tweet.lang,\n",
    "                    'tweet_source' : tweet.source, \n",
    "                    'tweet_hashtags' : [e['text'].encode('utf-8') for e in tweet._json['entities']['hashtags']],\n",
    "                    \"tweet_user_mentions_id\" : [e[\"id_str\"] for e in tweet.entities[\"user_mentions\"]],\n",
    "                    \"tweet_full_text\" : tweet.full_text.replace(\"\\n\",\" \").encode('utf-8'),\n",
    "                    \"user_id_str\" : tweet.user.id_str,\n",
    "                    'user_screen_name' : tweet.user.screen_name.encode('utf-8'),\n",
    "                    'user_name' : tweet.user.name.encode('utf-8'), \n",
    "                    'user_profile_description' : tweet.user.description.encode('utf-8'), \n",
    "                    'user_statuses_count' : tweet.user.statuses_count,\n",
    "                    'user_followers_count' : tweet.user.followers_count,\n",
    "                    'user_friends_count' : tweet.user.friends_count,\n",
    "                    'user_listed_count' : tweet.user.listed_count,\n",
    "                    'user_verified' : tweet.user.verified,  \n",
    "                    'user_time_zone' : tweet.user.time_zone, \n",
    "                    'geo_enabled' : tweet.user.geo_enabled,\n",
    "                    'user_timeline_lang' :tweet.user.lang,\n",
    "                    'geo' : tweet.geo,                 \n",
    "                    'user_location' : tweet.user.location.encode('utf-8'),\n",
    "                    'user_profile_created_at' : tweet.user.created_at,\n",
    "                    \"place_coordinates\" : (tweet.place if tweet.place==None else tweet.place.bounding_box.coordinates),\n",
    "                    \"place_id\" : (tweet.place if tweet.place==None else tweet.place.id),\n",
    "                    \"place_type\" : (tweet.place if tweet.place==None else tweet.place.place_type),\n",
    "                    \"place_country_code\" : (tweet.place if tweet.place==None else tweet.place.country_code),\n",
    "                   \"place_name\": (tweet.place if tweet.place==None else tweet.place.full_name),  # Add a comma at the end\n",
    "                    'coordinates' : tweet.coordinates,\n",
    "                    }, ignore_index = True)\n",
    "    \n",
    "return df\n",
    "    \n",
    "screen_name = \"EyaWor\"\n",
    "srk_df = user_tweets(screen_name)\n",
    "srk_df.to_csv(\"%s.csv\" %(screen_name)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "abb2cf58",
   "metadata": {},
   "outputs": [
    {
     "ename": "Forbidden",
     "evalue": "403 Forbidden\n453 - You currently have access to a subset of Twitter API v2 endpoints and limited v1.1 endpoints (e.g. media post, oauth) only. If you need access to this endpoint, you may need a different access level. You can learn more here: https://developer.twitter.com/en/portal/product",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mForbidden\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 61\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n\u001b[0;32m     60\u001b[0m screen_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEyaWor\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 61\u001b[0m srk_df \u001b[38;5;241m=\u001b[39m \u001b[43muser_tweets\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscreen_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     62\u001b[0m srk_df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (screen_name))\n",
      "Cell \u001b[1;32mIn[14], line 16\u001b[0m, in \u001b[0;36muser_tweets\u001b[1;34m(screen_name)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21muser_tweets\u001b[39m(screen_name):\n\u001b[0;32m     15\u001b[0m     all_tweets_info \u001b[38;5;241m=\u001b[39m tweepy\u001b[38;5;241m.\u001b[39mCursor(api\u001b[38;5;241m.\u001b[39muser_timeline, screen_name\u001b[38;5;241m=\u001b[39mscreen_name, tweet_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mextended\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mitems(\u001b[38;5;241m200\u001b[39m)\n\u001b[1;32m---> 16\u001b[0m     searched_tweets \u001b[38;5;241m=\u001b[39m [status \u001b[38;5;28;01mfor\u001b[39;00m status \u001b[38;5;129;01min\u001b[39;00m all_tweets_info]\n\u001b[0;32m     18\u001b[0m     COLS \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtweet_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtweet_created_at\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtweet_lang\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtweet_source\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtweet_hashtags\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtweet_user_mentions_id\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     19\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtweet_full_text\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser_id_str\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser_screen_name\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser_name\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser_profile_description\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser_statuses_count\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     20\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser_followers_count\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser_friends_count\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser_listed_count\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser_verified\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser_time_zone\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeo_enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     21\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser_timeline_lang\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeo\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser_location\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser_profile_created_at\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplace_coordinates\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplace_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplace_type\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     22\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplace_country_code\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplace_name\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoordinates\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     23\u001b[0m             ]\n\u001b[0;32m     25\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(columns\u001b[38;5;241m=\u001b[39mCOLS)\n",
      "Cell \u001b[1;32mIn[14], line 16\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21muser_tweets\u001b[39m(screen_name):\n\u001b[0;32m     15\u001b[0m     all_tweets_info \u001b[38;5;241m=\u001b[39m tweepy\u001b[38;5;241m.\u001b[39mCursor(api\u001b[38;5;241m.\u001b[39muser_timeline, screen_name\u001b[38;5;241m=\u001b[39mscreen_name, tweet_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mextended\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mitems(\u001b[38;5;241m200\u001b[39m)\n\u001b[1;32m---> 16\u001b[0m     searched_tweets \u001b[38;5;241m=\u001b[39m [status \u001b[38;5;28;01mfor\u001b[39;00m status \u001b[38;5;129;01min\u001b[39;00m all_tweets_info]\n\u001b[0;32m     18\u001b[0m     COLS \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtweet_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtweet_created_at\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtweet_lang\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtweet_source\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtweet_hashtags\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtweet_user_mentions_id\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     19\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtweet_full_text\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser_id_str\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser_screen_name\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser_name\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser_profile_description\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser_statuses_count\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     20\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser_followers_count\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser_friends_count\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser_listed_count\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser_verified\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser_time_zone\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeo_enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     21\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser_timeline_lang\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeo\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser_location\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser_profile_created_at\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplace_coordinates\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplace_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplace_type\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     22\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplace_country_code\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplace_name\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoordinates\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     23\u001b[0m             ]\n\u001b[0;32m     25\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(columns\u001b[38;5;241m=\u001b[39mCOLS)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tweepy\\cursor.py:86\u001b[0m, in \u001b[0;36mBaseIterator.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m---> 86\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tweepy\\cursor.py:286\u001b[0m, in \u001b[0;36mItemIterator.next\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    283\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_page \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpage_index \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_page) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Reached end of current page, get the next page...\u001b[39;00m\n\u001b[1;32m--> 286\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_page \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpage_iterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_page) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    288\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_page \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpage_iterator)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tweepy\\cursor.py:86\u001b[0m, in \u001b[0;36mBaseIterator.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m---> 86\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tweepy\\cursor.py:167\u001b[0m, in \u001b[0;36mIdIterator.next\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n\u001b[0;32m    166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 167\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmethod(max_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_id, parser\u001b[38;5;241m=\u001b[39mRawParser(), \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs)\n\u001b[0;32m    169\u001b[0m     model \u001b[38;5;241m=\u001b[39m ModelParser()\u001b[38;5;241m.\u001b[39mparse(\n\u001b[0;32m    170\u001b[0m         data, api \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmethod\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m,\n\u001b[0;32m    171\u001b[0m         payload_list\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmethod\u001b[38;5;241m.\u001b[39mpayload_list,\n\u001b[0;32m    172\u001b[0m         payload_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmethod\u001b[38;5;241m.\u001b[39mpayload_type\n\u001b[0;32m    173\u001b[0m     )\n\u001b[0;32m    174\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmethod\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m\u001b[38;5;241m.\u001b[39mparser\u001b[38;5;241m.\u001b[39mparse(\n\u001b[0;32m    175\u001b[0m         data, api \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmethod\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m,\n\u001b[0;32m    176\u001b[0m         payload_list\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmethod\u001b[38;5;241m.\u001b[39mpayload_list,\n\u001b[0;32m    177\u001b[0m         payload_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmethod\u001b[38;5;241m.\u001b[39mpayload_type\n\u001b[0;32m    178\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tweepy\\api.py:33\u001b[0m, in \u001b[0;36mpagination.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(method)\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m---> 33\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m method(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tweepy\\api.py:46\u001b[0m, in \u001b[0;36mpayload.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     44\u001b[0m kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpayload_list\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m payload_list\n\u001b[0;32m     45\u001b[0m kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpayload_type\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m payload_type\n\u001b[1;32m---> 46\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m method(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tweepy\\api.py:414\u001b[0m, in \u001b[0;36mAPI.user_timeline\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    373\u001b[0m \u001b[38;5;129m@pagination\u001b[39m(mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    374\u001b[0m \u001b[38;5;129m@payload\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mlist\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    375\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21muser_timeline\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    376\u001b[0m     \u001b[38;5;124;03m\"\"\"user_timeline(*, user_id, screen_name, since_id, count, max_id, \\\u001b[39;00m\n\u001b[0;32m    377\u001b[0m \u001b[38;5;124;03m                     trim_user, exclude_replies, include_rts)\u001b[39;00m\n\u001b[0;32m    378\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    412\u001b[0m \u001b[38;5;124;03m    https://developer.twitter.com/en/docs/twitter-api/v1/tweets/timelines/api-reference/get-statuses-user_timeline\u001b[39;00m\n\u001b[0;32m    413\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 414\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest(\n\u001b[0;32m    415\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGET\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstatuses/user_timeline\u001b[39m\u001b[38;5;124m'\u001b[39m, endpoint_parameters\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    416\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser_id\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscreen_name\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msince_id\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcount\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_id\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    417\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrim_user\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexclude_replies\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minclude_rts\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    418\u001b[0m         ), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    419\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tweepy\\api.py:271\u001b[0m, in \u001b[0;36mAPI.request\u001b[1;34m(self, method, endpoint, endpoint_parameters, params, headers, json_payload, parser, payload_list, payload_type, post_data, files, require_auth, return_cursors, upload_api, use_cache, **kwargs)\u001b[0m\n\u001b[0;32m    269\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Unauthorized(resp)\n\u001b[0;32m    270\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m403\u001b[39m:\n\u001b[1;32m--> 271\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Forbidden(resp)\n\u001b[0;32m    272\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m404\u001b[39m:\n\u001b[0;32m    273\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NotFound(resp)\n",
      "\u001b[1;31mForbidden\u001b[0m: 403 Forbidden\n453 - You currently have access to a subset of Twitter API v2 endpoints and limited v1.1 endpoints (e.g. media post, oauth) only. If you need access to this endpoint, you may need a different access level. You can learn more here: https://developer.twitter.com/en/portal/product"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tweepy\n",
    "\n",
    "# Your Twitter API keys\n",
    "consumer_key = \"F0iQh78LQ7i1XMD6hJ7uTOBew\"\n",
    "consumer_secret = \"u2Wn7BoxlXyWslv8amHCiiDLDlk51MEOydxw4FfUsBpMRSOBZ3\"\n",
    "access_token = \"1636765367451230209-HKRjedpRK34DEyc3U4Muw8dMjrrXTH\"\n",
    "access_token_secret = \"d9iCix5JoUeDtwV2dhMtNEw0mLIxl7PxfasydJzbrIE1l\"\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "def user_tweets(screen_name):\n",
    "    all_tweets_info = tweepy.Cursor(api.user_timeline, screen_name=screen_name, tweet_mode='extended').items(200)\n",
    "    searched_tweets = [status for status in all_tweets_info]\n",
    "\n",
    "    COLS = [\"tweet_id\", 'tweet_created_at', 'tweet_lang', 'tweet_source', \"tweet_hashtags\", \"tweet_user_mentions_id\",\n",
    "            \"tweet_full_text\", \"user_id_str\", 'user_screen_name', 'user_name', \"user_profile_description\", \"user_statuses_count\",\n",
    "            'user_followers_count', \"user_friends_count\", \"user_listed_count\", \"user_verified\", \"user_time_zone\", \"geo_enabled\",\n",
    "            \"user_timeline_lang\", \"geo\", 'user_location', \"user_profile_created_at\", \"place_coordinates\", \"place_id\", \"place_type\",\n",
    "            \"place_country_code\", \"place_name\", \"coordinates\"\n",
    "            ]\n",
    "\n",
    "    df = pd.DataFrame(columns=COLS)\n",
    "\n",
    "    for tweet in searched_tweets:\n",
    "        df = df.append({\"tweet_id\" : tweet.id_str,\n",
    "                    'tweet_created_at' : tweet.created_at,\n",
    "                    'tweet_lang' : tweet.lang,\n",
    "                    'tweet_source' : tweet.source, \n",
    "                    'tweet_hashtags' : [e['text'].encode('utf-8') for e in tweet._json['entities']['hashtags']],\n",
    "                    \"tweet_user_mentions_id\" : [e[\"id_str\"] for e in tweet.entities[\"user_mentions\"]],\n",
    "                    \"tweet_full_text\" : tweet.full_text.replace(\"\\n\",\" \").encode('utf-8'),\n",
    "                    \"user_id_str\" : tweet.user.id_str,\n",
    "                    'user_screen_name' : tweet.user.screen_name.encode('utf-8'),\n",
    "                    'user_name' : tweet.user.name.encode('utf-8'), \n",
    "                    'user_profile_description' : tweet.user.description.encode('utf-8'), \n",
    "                    'user_statuses_count' : tweet.user.statuses_count,\n",
    "                    'user_followers_count' : tweet.user.followers_count,\n",
    "                    'user_friends_count' : tweet.user.friends_count,\n",
    "                    'user_listed_count' : tweet.user.listed_count,\n",
    "                    'user_verified' : tweet.user.verified,  \n",
    "                    'user_time_zone' : tweet.user.time_zone, \n",
    "                    'geo_enabled' : tweet.user.geo_enabled,\n",
    "                    'user_timeline_lang' :tweet.user.lang,\n",
    "                    'geo' : tweet.geo,                 \n",
    "                    'user_location' : tweet.user.location.encode('utf-8'),\n",
    "                    'user_profile_created_at' : tweet.user.created_at,\n",
    "                    \"place_coordinates\" : (tweet.place if tweet.place==None else tweet.place.bounding_box.coordinates),\n",
    "                    \"place_id\" : (tweet.place if tweet.place==None else tweet.place.id),\n",
    "                    \"place_type\" : (tweet.place if tweet.place==None else tweet.place.place_type),\n",
    "                    \"place_country_code\" : (tweet.place if tweet.place==None else tweet.place.country_code),\n",
    "                   \"place_name\": (tweet.place if tweet.place==None else tweet.place.full_name),  # Add a comma at the end\n",
    "                    'coordinates' : tweet.coordinates,\n",
    "                    }, ignore_index = True)\n",
    "\n",
    "    return df\n",
    "\n",
    "screen_name = \"EyaWor\"\n",
    "srk_df = user_tweets(screen_name)\n",
    "srk_df.to_csv(\"%s.csv\" % (screen_name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a75f552e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting searchtweets\n",
      "  Downloading searchtweets-1.7.6-py3-none-any.whl (29 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from searchtweets) (2.28.1)\n",
      "Collecting tweet-parser\n",
      "  Downloading tweet_parser-1.13.2-py3-none-any.whl (34 kB)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from searchtweets) (6.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from requests->searchtweets) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from requests->searchtweets) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from requests->searchtweets) (2023.7.22)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from requests->searchtweets) (3.4)\n",
      "Installing collected packages: tweet-parser, searchtweets\n",
      "Successfully installed searchtweets-1.7.6 tweet-parser-1.13.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install searchtweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "565f56a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'search-tweets-python'...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///C:/Users/eyawo/search-tweets-python\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: requests in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from searchtweets==1.7.7) (2.28.1)\n",
      "Requirement already satisfied: tweet_parser in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from searchtweets==1.7.7) (1.13.2)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from searchtweets==1.7.7) (6.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from requests->searchtweets==1.7.7) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from requests->searchtweets==1.7.7) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from requests->searchtweets==1.7.7) (2023.7.22)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from requests->searchtweets==1.7.7) (2.0.4)\n",
      "Installing collected packages: searchtweets\n",
      "  Attempting uninstall: searchtweets\n",
      "    Found existing installation: searchtweets 1.7.6\n",
      "    Uninstalling searchtweets-1.7.6:\n",
      "      Successfully uninstalled searchtweets-1.7.6\n",
      "  Running setup.py develop for searchtweets\n",
      "Successfully installed searchtweets-1.7.7\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/twitterdev/search-tweets-python\n",
    "!cd search-tweets-python\n",
    "!pip install -e search-tweets-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5708fba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyyaml in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (6.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyyaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6c7dfb67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consumer Key: \n",
      "Consumer Secret: \n",
      "Endpoint: https://api.twitter.com/1.1/tweets/search/30day/dev/myproject_tweets.json\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "import os\n",
    "\n",
    "# Change the current working directory to the directory containing config.yaml\n",
    "os.chdir('C:/Users/eyawo/OneDrive/Bureau/summer internship/NB')\n",
    "\n",
    "# Now you can load the configuration\n",
    "with open('config.yaml', 'r') as config_file:\n",
    "    config = yaml.safe_load(config_file)\n",
    "\n",
    "# Now you can access the configuration settings\n",
    "search_tweets_api_config = config.get('search_tweets_api', {})\n",
    "consumer_key = search_tweets_api_config.get('consumer_key', '')\n",
    "consumer_secret = search_tweets_api_config.get('consumer_secret', '')\n",
    "endpoint = search_tweets_api_config.get('endpoint', '')\n",
    "\n",
    "print(\"Consumer Key:\", consumer_key)\n",
    "print(\"Consumer Secret:\", consumer_secret)\n",
    "print(\"Endpoint:\", endpoint)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2abccd5f",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2905738923.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[55], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    search_tweets_api:\u001b[0m\n\u001b[1;37m                      ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "search_tweets_api:\n",
    "  account_type: premium\n",
    "  endpoint: \"https://api.twitter.com/1.1/tweets/search/30day/dev/myproject_tweets.json\"\n",
    "consumer_key: \"F0iQh78LQ7i1XMD6hJ7uTOBew\"\n",
    "consumer_secret: \"u2Wn7BoxlXyWslv8amHCiiDLDlk51MEOydxw4FfUsBpMRSOBZ3\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9bcf1e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: searchtweets in c:\\users\\eyawo\\search-tweets-python (1.7.7)\n",
      "Requirement already satisfied: requests in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from searchtweets) (2.28.1)\n",
      "Requirement already satisfied: tweet_parser in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from searchtweets) (1.13.2)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from searchtweets) (6.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from requests->searchtweets) (2023.7.22)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from requests->searchtweets) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from requests->searchtweets) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from requests->searchtweets) (2.0.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install searchtweets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "06da0643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                       Version         Editable project location\n",
      "----------------------------- --------------- -----------------------------------\n",
      "alabaster                     0.7.12\n",
      "anaconda-client               1.11.2\n",
      "anaconda-navigator            2.4.0\n",
      "anaconda-project              0.11.1\n",
      "anyio                         3.5.0\n",
      "appdirs                       1.4.4\n",
      "argon2-cffi                   21.3.0\n",
      "argon2-cffi-bindings          21.2.0\n",
      "arrow                         1.2.3\n",
      "astroid                       2.14.2\n",
      "astropy                       5.1\n",
      "asttokens                     2.0.5\n",
      "atomicwrites                  1.4.0\n",
      "attrs                         22.1.0\n",
      "Automat                       20.2.0\n",
      "autopep8                      1.6.0\n",
      "Babel                         2.11.0\n",
      "backcall                      0.2.0\n",
      "backports.functools-lru-cache 1.6.4\n",
      "backports.tempfile            1.0\n",
      "backports.weakref             1.0.post1\n",
      "bcrypt                        3.2.0\n",
      "beautifulsoup4                4.11.1\n",
      "binaryornot                   0.4.4\n",
      "black                         22.6.0\n",
      "bleach                        4.1.0\n",
      "bokeh                         2.4.3\n",
      "boltons                       23.0.0\n",
      "Bottleneck                    1.3.5\n",
      "brotlipy                      0.7.0\n",
      "certifi                       2023.7.22\n",
      "cffi                          1.15.1\n",
      "chardet                       4.0.0\n",
      "charset-normalizer            2.0.4\n",
      "click                         8.0.4\n",
      "cloudpickle                   2.0.0\n",
      "clyent                        1.2.2\n",
      "colorama                      0.4.6\n",
      "colorcet                      3.0.1\n",
      "comm                          0.1.2\n",
      "conda                         23.3.1\n",
      "conda-build                   3.24.0\n",
      "conda-content-trust           0.1.3\n",
      "conda-pack                    0.6.0\n",
      "conda-package-handling        2.0.2\n",
      "conda_package_streaming       0.7.0\n",
      "conda-repo-cli                1.0.41\n",
      "conda-token                   0.4.0\n",
      "conda-verify                  3.4.2\n",
      "constantly                    15.1.0\n",
      "contourpy                     1.0.5\n",
      "cookiecutter                  1.7.3\n",
      "cryptography                  39.0.1\n",
      "cssselect                     1.1.0\n",
      "cycler                        0.11.0\n",
      "cytoolz                       0.12.0\n",
      "daal4py                       2023.0.2\n",
      "dask                          2022.7.0\n",
      "datashader                    0.14.4\n",
      "datashape                     0.5.4\n",
      "debugpy                       1.5.1\n",
      "decorator                     5.1.1\n",
      "defusedxml                    0.7.1\n",
      "diff-match-patch              20200713\n",
      "dill                          0.3.6\n",
      "distributed                   2022.7.0\n",
      "docstring-to-markdown         0.11\n",
      "docutils                      0.18.1\n",
      "entrypoints                   0.4\n",
      "et-xmlfile                    1.1.0\n",
      "executing                     0.8.3\n",
      "fastjsonschema                2.16.2\n",
      "filelock                      3.9.0\n",
      "flake8                        6.0.0\n",
      "Flask                         2.2.2\n",
      "flit_core                     3.6.0\n",
      "fonttools                     4.25.0\n",
      "fsspec                        2022.11.0\n",
      "future                        0.18.3\n",
      "gensim                        4.3.0\n",
      "glob2                         0.7\n",
      "greenlet                      2.0.1\n",
      "h5py                          3.7.0\n",
      "HeapDict                      1.0.1\n",
      "holoviews                     1.15.4\n",
      "huggingface-hub               0.10.1\n",
      "hvplot                        0.8.2\n",
      "hyperlink                     21.0.0\n",
      "idna                          3.4\n",
      "imagecodecs                   2021.8.26\n",
      "imageio                       2.26.0\n",
      "imagesize                     1.4.1\n",
      "imbalanced-learn              0.10.1\n",
      "importlib-metadata            4.11.3\n",
      "incremental                   21.3.0\n",
      "inflection                    0.5.1\n",
      "iniconfig                     1.1.1\n",
      "intake                        0.6.7\n",
      "intervaltree                  3.1.0\n",
      "ipykernel                     6.19.2\n",
      "ipython                       8.10.0\n",
      "ipython-genutils              0.2.0\n",
      "ipywidgets                    7.6.5\n",
      "isort                         5.9.3\n",
      "itemadapter                   0.3.0\n",
      "itemloaders                   1.0.4\n",
      "itsdangerous                  2.0.1\n",
      "jedi                          0.18.1\n",
      "jellyfish                     0.9.0\n",
      "Jinja2                        3.1.2\n",
      "jinja2-time                   0.2.0\n",
      "jmespath                      0.10.0\n",
      "joblib                        1.1.1\n",
      "json5                         0.9.6\n",
      "jsonpatch                     1.32\n",
      "jsonpointer                   2.1\n",
      "jsonschema                    4.17.3\n",
      "jupyter                       1.0.0\n",
      "jupyter_client                7.3.4\n",
      "jupyter-console               6.6.2\n",
      "jupyter_core                  5.2.0\n",
      "jupyter-server                1.23.4\n",
      "jupyterlab                    3.5.3\n",
      "jupyterlab-pygments           0.1.2\n",
      "jupyterlab_server             2.19.0\n",
      "jupyterlab-widgets            1.0.0\n",
      "keyring                       23.4.0\n",
      "kiwisolver                    1.4.4\n",
      "lazy-object-proxy             1.6.0\n",
      "libarchive-c                  2.9\n",
      "llvmlite                      0.39.1\n",
      "locket                        1.0.0\n",
      "lxml                          4.9.1\n",
      "lz4                           3.1.3\n",
      "Markdown                      3.4.1\n",
      "MarkupSafe                    2.1.1\n",
      "matplotlib                    3.7.0\n",
      "matplotlib-inline             0.1.6\n",
      "mccabe                        0.7.0\n",
      "menuinst                      1.4.19\n",
      "mistune                       0.8.4\n",
      "mkl-fft                       1.3.1\n",
      "mkl-random                    1.2.2\n",
      "mkl-service                   2.4.0\n",
      "mock                          4.0.3\n",
      "mpmath                        1.2.1\n",
      "msgpack                       1.0.3\n",
      "multipledispatch              0.6.0\n",
      "munkres                       1.1.4\n",
      "mypy-extensions               0.4.3\n",
      "navigator-updater             0.3.0\n",
      "nbclassic                     0.5.2\n",
      "nbclient                      0.5.13\n",
      "nbconvert                     6.5.4\n",
      "nbformat                      5.7.0\n",
      "nest-asyncio                  1.5.6\n",
      "networkx                      2.8.4\n",
      "nltk                          3.7\n",
      "notebook                      6.5.2\n",
      "notebook_shim                 0.2.2\n",
      "numba                         0.56.4\n",
      "numexpr                       2.8.4\n",
      "numpy                         1.23.5\n",
      "numpydoc                      1.5.0\n",
      "oauthlib                      3.2.2\n",
      "openpyxl                      3.0.10\n",
      "packaging                     22.0\n",
      "pandas                        1.5.3\n",
      "pandocfilters                 1.5.0\n",
      "panel                         0.14.3\n",
      "param                         1.12.3\n",
      "paramiko                      2.8.1\n",
      "parsel                        1.6.0\n",
      "parso                         0.8.3\n",
      "partd                         1.2.0\n",
      "pathlib                       1.0.1\n",
      "pathspec                      0.10.3\n",
      "patsy                         0.5.3\n",
      "pep8                          1.7.1\n",
      "pexpect                       4.8.0\n",
      "pickleshare                   0.7.5\n",
      "Pillow                        9.4.0\n",
      "pip                           22.3.1\n",
      "pkginfo                       1.9.6\n",
      "platformdirs                  2.5.2\n",
      "plotly                        5.9.0\n",
      "pluggy                        1.0.0\n",
      "ply                           3.11\n",
      "pooch                         1.4.0\n",
      "poyo                          0.5.0\n",
      "prometheus-client             0.14.1\n",
      "prompt-toolkit                3.0.36\n",
      "Protego                       0.1.16\n",
      "psutil                        5.9.0\n",
      "ptyprocess                    0.7.0\n",
      "pure-eval                     0.2.2\n",
      "py                            1.11.0\n",
      "pyasn1                        0.4.8\n",
      "pyasn1-modules                0.2.8\n",
      "pycodestyle                   2.10.0\n",
      "pycosat                       0.6.4\n",
      "pycparser                     2.21\n",
      "pyct                          0.5.0\n",
      "pycurl                        7.45.1\n",
      "PyDispatcher                  2.0.5\n",
      "pydocstyle                    6.3.0\n",
      "pyerfa                        2.0.0\n",
      "pyflakes                      3.0.1\n",
      "Pygments                      2.11.2\n",
      "PyHamcrest                    2.0.2\n",
      "PyJWT                         2.4.0\n",
      "pylint                        2.16.2\n",
      "pylint-venv                   2.3.0\n",
      "pyls-spyder                   0.4.0\n",
      "PyNaCl                        1.5.0\n",
      "pyodbc                        4.0.34\n",
      "pyOpenSSL                     23.0.0\n",
      "pyparsing                     3.0.9\n",
      "PyQt5                         5.15.7\n",
      "PyQt5-sip                     12.11.0\n",
      "PyQtWebEngine                 5.15.4\n",
      "pyrsistent                    0.18.0\n",
      "PySocks                       1.7.1\n",
      "pytest                        7.1.2\n",
      "python-dateutil               2.8.2\n",
      "python-lsp-black              1.2.1\n",
      "python-lsp-jsonrpc            1.0.0\n",
      "python-lsp-server             1.7.1\n",
      "python-slugify                5.0.2\n",
      "python-snappy                 0.6.1\n",
      "pytoolconfig                  1.2.5\n",
      "pytz                          2022.7\n",
      "pyviz-comms                   2.0.2\n",
      "PyWavelets                    1.4.1\n",
      "pywin32                       305.1\n",
      "pywin32-ctypes                0.2.0\n",
      "pywinpty                      2.0.10\n",
      "PyYAML                        6.0\n",
      "pyzmq                         23.2.0\n",
      "QDarkStyle                    3.0.2\n",
      "qstylizer                     0.2.2\n",
      "QtAwesome                     1.2.2\n",
      "qtconsole                     5.4.0\n",
      "QtPy                          2.2.0\n",
      "queuelib                      1.5.0\n",
      "regex                         2022.7.9\n",
      "requests                      2.28.1\n",
      "requests-file                 1.5.1\n",
      "requests-oauthlib             1.3.1\n",
      "requests-toolbelt             0.9.1\n",
      "rope                          1.7.0\n",
      "Rtree                         1.0.1\n",
      "ruamel.yaml                   0.17.21\n",
      "ruamel.yaml.clib              0.2.6\n",
      "ruamel-yaml-conda             0.17.21\n",
      "scikit-image                  0.19.3\n",
      "scikit-learn                  1.2.1\n",
      "scikit-learn-intelex          20230228.214818\n",
      "scipy                         1.10.0\n",
      "Scrapy                        2.8.0\n",
      "seaborn                       0.12.2\n",
      "searchtweets                  1.7.7           c:\\users\\eyawo\\search-tweets-python\n",
      "Send2Trash                    1.8.0\n",
      "service-identity              18.1.0\n",
      "setuptools                    65.6.3\n",
      "sip                           6.6.2\n",
      "six                           1.16.0\n",
      "smart-open                    5.2.1\n",
      "sniffio                       1.2.0\n",
      "snowballstemmer               2.2.0\n",
      "sortedcontainers              2.4.0\n",
      "soupsieve                     2.3.2.post1\n",
      "Sphinx                        5.0.2\n",
      "sphinxcontrib-applehelp       1.0.2\n",
      "sphinxcontrib-devhelp         1.0.2\n",
      "sphinxcontrib-htmlhelp        2.0.0\n",
      "sphinxcontrib-jsmath          1.0.1\n",
      "sphinxcontrib-qthelp          1.0.3\n",
      "sphinxcontrib-serializinghtml 1.1.5\n",
      "spyder                        5.4.1\n",
      "spyder-kernels                2.4.1\n",
      "SQLAlchemy                    1.4.39\n",
      "stack-data                    0.2.0\n",
      "statsmodels                   0.13.5\n",
      "sympy                         1.11.1\n",
      "tables                        3.7.0\n",
      "tabulate                      0.8.10\n",
      "TBB                           0.2\n",
      "tblib                         1.7.0\n",
      "tenacity                      8.0.1\n",
      "terminado                     0.17.1\n",
      "text-unidecode                1.3\n",
      "textdistance                  4.2.1\n",
      "threadpoolctl                 2.2.0\n",
      "three-merge                   0.1.1\n",
      "tifffile                      2021.7.2\n",
      "tinycss2                      1.2.1\n",
      "tldextract                    3.2.0\n",
      "tokenizers                    0.11.4\n",
      "toml                          0.10.2\n",
      "tomli                         2.0.1\n",
      "tomlkit                       0.11.1\n",
      "toolz                         0.12.0\n",
      "torch                         1.12.1\n",
      "tornado                       6.1\n",
      "tqdm                          4.64.1\n",
      "traitlets                     5.7.1\n",
      "transformers                  4.24.0\n",
      "tweepy                        4.14.0\n",
      "tweet-parser                  1.13.2\n",
      "Twisted                       22.2.0\n",
      "twisted-iocpsupport           1.0.2\n",
      "typing_extensions             4.4.0\n",
      "ujson                         5.4.0\n",
      "Unidecode                     1.2.0\n",
      "urllib3                       1.26.14\n",
      "w3lib                         1.21.0\n",
      "watchdog                      2.1.6\n",
      "wcwidth                       0.2.5\n",
      "webencodings                  0.5.1\n",
      "websocket-client              0.58.0\n",
      "Werkzeug                      2.2.2\n",
      "whatthepatch                  1.0.2\n",
      "wheel                         0.38.4\n",
      "widgetsnbextension            3.5.2\n",
      "win-inet-pton                 1.1.0\n",
      "wincertstore                  0.2\n",
      "wrapt                         1.14.1\n",
      "xarray                        2022.11.0\n",
      "xlwings                       0.29.1\n",
      "yapf                          0.31.0\n",
      "zict                          2.1.0\n",
      "zipp                          3.11.0\n",
      "zope.interface                5.4.0\n",
      "zstandard                     0.19.0\n"
     ]
    }
   ],
   "source": [
    "!pip list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d1f6586f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The system cannot find the path specified.\n"
     ]
    }
   ],
   "source": [
    "!/path/to/python_executable -m pip install searchtweets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3f226635",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'searchtweets'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[65], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msearchtweets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_credentials\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Set environment variables\u001b[39;00m\n\u001b[0;32m      5\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSEARCHTWEETS_ENDPOINT\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://api.twitter.com/1.1/tweets/search/30day/dev/myproject_tweets.json\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'searchtweets'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from searchtweets import load_credentials\n",
    "\n",
    "# Set environment variables\n",
    "os.environ['SEARCHTWEETS_ENDPOINT'] = \"https://api.twitter.com/1.1/tweets/search/30day/dev/myproject_tweets.json\"\n",
    "os.environ['SEARCHTWEETS_USERNAME'] = \"EyaWor\"\n",
    "#os.environ['SEARCHTWEETS_PASSWORD'] = \"your_password_value\"\n",
    "os.environ['SEARCHTWEETS_BEARER_TOKEN'] = \"AAAAAAAAAAAAAAAAAAAAAJOYpQEAAAAA6rQOJrghOPQlehWaJKfHMFfVsK8%3DXdSr5gkNxgzQFEoiVA1kp0DtgrWUIKALWq35jVSUmM5v7ixvLV\"\n",
    "os.environ['SEARCHTWEETS_ACCOUNT_TYPE'] = \"your_account_type_value\"\n",
    "os.environ['SEARCHTWEETS_CONSUMER_KEY'] = \"F0iu2Wn7BoxlXyWslv8amHCiiDLDlk51MEOydxw4FfUsBpMRSOBZ3\"\n",
    "\n",
    "# Load credentialsconsumer_key = \"F0iQh78LQ7i1XMD6hJ7uTOBew\"\n",
    "consumer_secret = \"u2Wn7BoxlXyWslv8amHCiiDLDlk51MEOydxw4FfUsBpMRSOBZ3\"\n",
    "premium_search_args = load_credentials(filename=\"your_credentials_file.yaml\", \n",
    "                                       yaml_key=\"your_config_key\", \n",
    "                                       env_overwrite=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efed5af9",
   "metadata": {},
   "source": [
    "# TWEETER SCRAPPING USING GIT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93485498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* main\n",
      "  remotes/origin/HEAD -> origin/main\n",
      "  remotes/origin/add-license-1\n",
      "  remotes/origin/code-refactor-october\n",
      "  remotes/origin/custom-profile-loader-feature\n",
      "  remotes/origin/directory-fix\n",
      "  remotes/origin/json-write-fix\n",
      "  remotes/origin/main\n",
      "  remotes/origin/readme-installation-fix\n",
      "  remotes/origin/v3.0.1\n",
      "  remotes/origin/v3.1.3\n",
      "  remotes/origin/v3.2.3\n",
      "  remotes/origin/v4.0.0\n",
      "  remotes/origin/v4.0.1\n",
      "  remotes/origin/v4.0.2\n",
      "  remotes/origin/v4.1.2\n",
      "  remotes/origin/v4.1.3\n",
      "  remotes/origin/v4.1.4\n",
      "  remotes/origin/version_2.0\n"
     ]
    }
   ],
   "source": [
    "!cd twitter-scraper-selenium && git branch -a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0b3e966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already up to date.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "From https://github.com/shaikhsajid1111/twitter-scraper-selenium\n",
      " * branch            main       -> FETCH_HEAD\n"
     ]
    }
   ],
   "source": [
    "!cd twitter-scraper-selenium && git pull origin main\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "790ebf4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eyawo\\anaconda3\\pkgs\\python-3.10.9-h966fe2a_1\\info\\test\\tests\\distutils\n",
      "Requirement already satisfied: requests in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (2.28.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from requests) (2023.7.22)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from requests) (1.26.14)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Change the current working directory\n",
    "new_directory = r'C:\\Users\\eyawo\\Downloads'\n",
    "os.chdir(new_directory)\n",
    "%cd C:\\Users\\eyawo\\anaconda3\\pkgs\\python-3.10.9-h966fe2a_1\\info\\test\\tests\\distutils\n",
    "!pip install requests\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4d241206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (2.28.1)\n",
      "Collecting requests\n",
      "  Using cached requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from requests) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from requests) (2023.7.22)\n",
      "Installing collected packages: requests\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.28.1\n",
      "    Uninstalling requests-2.28.1:\n",
      "      Successfully uninstalled requests-2.28.1\n",
      "Successfully installed requests-2.31.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "conda-repo-cli 1.0.41 requires requests_mock, which is not installed.\n",
      "conda-repo-cli 1.0.41 requires clyent==1.2.1, but you have clyent 1.2.2 which is incompatible.\n",
      "conda-repo-cli 1.0.41 requires nbformat==5.4.0, but you have nbformat 5.7.0 which is incompatible.\n",
      "conda-repo-cli 1.0.41 requires requests==2.28.1, but you have requests 2.31.0 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade requests\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cfe5df35-7ba4-4a7b-a144-744dae875bfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: twitter-scraper-selenium in c:\\users\\eyawo\\appdata\\roaming\\python\\python311\\site-packages (5.0.0)\n",
      "Requirement already satisfied: python-dateutil==2.8.2 in c:\\users\\eyawo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from twitter-scraper-selenium) (2.8.2)\n",
      "Requirement already satisfied: selenium==4.7.0 in c:\\users\\eyawo\\appdata\\roaming\\python\\python311\\site-packages (from twitter-scraper-selenium) (4.7.0)\n",
      "Requirement already satisfied: selenium-wire==5.1.0 in c:\\users\\eyawo\\appdata\\roaming\\python\\python311\\site-packages (from twitter-scraper-selenium) (5.1.0)\n",
      "Requirement already satisfied: webdriver-manager==3.2.2 in c:\\users\\eyawo\\appdata\\roaming\\python\\python311\\site-packages (from twitter-scraper-selenium) (3.2.2)\n",
      "Requirement already satisfied: fake-headers==1.0.2 in c:\\users\\eyawo\\appdata\\roaming\\python\\python311\\site-packages (from twitter-scraper-selenium) (1.0.2)\n",
      "Requirement already satisfied: requests==2.27.1 in c:\\users\\eyawo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from twitter-scraper-selenium) (2.27.1)\n",
      "Requirement already satisfied: bs4 in c:\\users\\eyawo\\appdata\\roaming\\python\\python311\\site-packages (from fake-headers==1.0.2->twitter-scraper-selenium) (0.0.1)\n",
      "Requirement already satisfied: html5lib in c:\\users\\eyawo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from fake-headers==1.0.2->twitter-scraper-selenium) (1.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\eyawo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil==2.8.2->twitter-scraper-selenium) (1.16.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\eyawo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests==2.27.1->twitter-scraper-selenium) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\eyawo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests==2.27.1->twitter-scraper-selenium) (2023.7.22)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\eyawo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests==2.27.1->twitter-scraper-selenium) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\eyawo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests==2.27.1->twitter-scraper-selenium) (3.4)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\eyawo\\appdata\\roaming\\python\\python311\\site-packages (from selenium==4.7.0->twitter-scraper-selenium) (0.22.2)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\eyawo\\appdata\\roaming\\python\\python311\\site-packages (from selenium==4.7.0->twitter-scraper-selenium) (0.10.3)\n",
      "Requirement already satisfied: blinker>=1.4 in c:\\users\\eyawo\\appdata\\roaming\\python\\python311\\site-packages (from selenium-wire==5.1.0->twitter-scraper-selenium) (1.6.2)\n",
      "Requirement already satisfied: brotli>=1.0.9 in c:\\users\\eyawo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from selenium-wire==5.1.0->twitter-scraper-selenium) (1.0.9)\n",
      "Requirement already satisfied: kaitaistruct>=0.7 in c:\\users\\eyawo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from selenium-wire==5.1.0->twitter-scraper-selenium) (0.10)\n",
      "Requirement already satisfied: pyasn1>=0.3.1 in c:\\users\\eyawo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from selenium-wire==5.1.0->twitter-scraper-selenium) (0.5.0)\n",
      "Requirement already satisfied: pyOpenSSL>=22.0.0 in c:\\users\\eyawo\\appdata\\roaming\\python\\python311\\site-packages (from selenium-wire==5.1.0->twitter-scraper-selenium) (23.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.4.2 in c:\\users\\eyawo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from selenium-wire==5.1.0->twitter-scraper-selenium) (3.1.1)\n",
      "Requirement already satisfied: pysocks>=1.7.1 in c:\\users\\eyawo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from selenium-wire==5.1.0->twitter-scraper-selenium) (1.7.1)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\eyawo\\appdata\\roaming\\python\\python311\\site-packages (from selenium-wire==5.1.0->twitter-scraper-selenium) (1.2.0)\n",
      "Requirement already satisfied: zstandard>=0.14.1 in c:\\users\\eyawo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from selenium-wire==5.1.0->twitter-scraper-selenium) (0.21.0)\n",
      "Requirement already satisfied: h2>=4.0 in c:\\users\\eyawo\\appdata\\roaming\\python\\python311\\site-packages (from selenium-wire==5.1.0->twitter-scraper-selenium) (4.1.0)\n",
      "Requirement already satisfied: hyperframe>=6.0 in c:\\users\\eyawo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from selenium-wire==5.1.0->twitter-scraper-selenium) (6.0.1)\n",
      "Requirement already satisfied: pydivert>=2.0.3 in c:\\users\\eyawo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from selenium-wire==5.1.0->twitter-scraper-selenium) (2.1.0)\n",
      "Requirement already satisfied: configparser in c:\\users\\eyawo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from webdriver-manager==3.2.2->twitter-scraper-selenium) (6.0.0)\n",
      "Requirement already satisfied: crayons in c:\\users\\eyawo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from webdriver-manager==3.2.2->twitter-scraper-selenium) (0.4.0)\n",
      "Requirement already satisfied: hpack<5,>=4.0 in c:\\users\\eyawo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from h2>=4.0->selenium-wire==5.1.0->twitter-scraper-selenium) (4.0.0)\n",
      "Requirement already satisfied: cryptography!=40.0.0,!=40.0.1,<42,>=38.0.0 in c:\\users\\eyawo\\appdata\\roaming\\python\\python311\\site-packages (from pyOpenSSL>=22.0.0->selenium-wire==5.1.0->twitter-scraper-selenium) (41.0.3)\n",
      "Requirement already satisfied: attrs>=20.1.0 in c:\\users\\eyawo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from trio~=0.17->selenium==4.7.0->twitter-scraper-selenium) (23.1.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\eyawo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from trio~=0.17->selenium==4.7.0->twitter-scraper-selenium) (2.4.0)\n",
      "Requirement already satisfied: outcome in c:\\users\\eyawo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from trio~=0.17->selenium==4.7.0->twitter-scraper-selenium) (1.2.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\eyawo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from trio~=0.17->selenium==4.7.0->twitter-scraper-selenium) (1.3.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\eyawo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from trio~=0.17->selenium==4.7.0->twitter-scraper-selenium) (1.15.1)\n",
      "Requirement already satisfied: exceptiongroup in c:\\users\\eyawo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from trio-websocket~=0.9->selenium==4.7.0->twitter-scraper-selenium) (1.1.3)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\eyawo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from wsproto>=0.14->selenium-wire==5.1.0->twitter-scraper-selenium) (0.14.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\eyawo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from bs4->fake-headers==1.0.2->twitter-scraper-selenium) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\eyawo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from crayons->webdriver-manager==3.2.2->twitter-scraper-selenium) (0.4.6)\n",
      "Requirement already satisfied: webencodings in c:\\users\\eyawo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from html5lib->fake-headers==1.0.2->twitter-scraper-selenium) (0.5.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\eyawo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium==4.7.0->twitter-scraper-selenium) (2.21)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\eyawo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from beautifulsoup4->bs4->fake-headers==1.0.2->twitter-scraper-selenium) (2.4.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: Loading egg at c:\\users\\eyawo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages\\foobar-1.0-py3.11.egg is deprecated. pip 23.3 will enforce this behaviour change. A possible replacement is to use pip for package installation..\n"
     ]
    }
   ],
   "source": [
    "!pip3 install twitter-scraper-selenium --user\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c18a6ec5-fca5-4241-adaf-b57a903a548d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting requests==2.27.1\n",
      "  Using cached requests-2.27.1-py2.py3-none-any.whl (63 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from requests==2.27.1) (2023.7.22)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from requests==2.27.1) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from requests==2.27.1) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from requests==2.27.1) (3.4)\n",
      "Installing collected packages: requests\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.31.0\n",
      "    Uninstalling requests-2.31.0:\n",
      "      Successfully uninstalled requests-2.31.0\n",
      "Successfully installed requests-2.27.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "conda-repo-cli 1.0.41 requires requests_mock, which is not installed.\n",
      "jupyterlab-server 2.19.0 requires requests>=2.28, but you have requests 2.27.1 which is incompatible.\n",
      "conda-repo-cli 1.0.41 requires clyent==1.2.1, but you have clyent 1.2.2 which is incompatible.\n",
      "conda-repo-cli 1.0.41 requires nbformat==5.4.0, but you have nbformat 5.7.0 which is incompatible.\n",
      "conda-repo-cli 1.0.41 requires requests==2.28.1, but you have requests 2.27.1 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install requests==2.27.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ad2ac781-b473-4c55-bad4-1df7cd1ead68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting twitter-scraper-selenium\n",
      "  Using cached twitter_scraper_selenium-5.0.0-py3-none-any.whl (33 kB)\n",
      "Collecting webdriver-manager==3.2.2\n",
      "  Using cached webdriver_manager-3.2.2-py2.py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: requests==2.27.1 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from twitter-scraper-selenium) (2.27.1)\n",
      "Collecting selenium-wire==5.1.0\n",
      "  Using cached selenium_wire-5.1.0-py3-none-any.whl (239 kB)\n",
      "Collecting fake-headers==1.0.2\n",
      "  Using cached fake_headers-1.0.2-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: python-dateutil==2.8.2 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from twitter-scraper-selenium) (2.8.2)\n",
      "Collecting selenium==4.7.0\n",
      "  Using cached selenium-4.7.0-py3-none-any.whl (6.3 MB)\n",
      "Collecting bs4\n",
      "  Using cached bs4-0.0.1.tar.gz (1.1 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting html5lib\n",
      "  Using cached html5lib-1.1-py2.py3-none-any.whl (112 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from python-dateutil==2.8.2->twitter-scraper-selenium) (1.16.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from requests==2.27.1->twitter-scraper-selenium) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from requests==2.27.1->twitter-scraper-selenium) (3.4)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from requests==2.27.1->twitter-scraper-selenium) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from requests==2.27.1->twitter-scraper-selenium) (2023.7.22)\n",
      "Collecting trio-websocket~=0.9\n",
      "  Using cached trio_websocket-0.10.3-py3-none-any.whl (17 kB)\n",
      "Collecting trio~=0.17\n",
      "  Using cached trio-0.22.2-py3-none-any.whl (400 kB)\n",
      "Collecting brotli>=1.0.9\n",
      "  Downloading Brotli-1.0.9-cp310-cp310-win_amd64.whl (383 kB)\n",
      "     ------------------------------------ 383.3/383.3 kB 821.8 kB/s eta 0:00:00\n",
      "Requirement already satisfied: zstandard>=0.14.1 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from selenium-wire==5.1.0->twitter-scraper-selenium) (0.19.0)\n",
      "Collecting pydivert>=2.0.3\n",
      "  Using cached pydivert-2.1.0-py2.py3-none-any.whl (104 kB)\n",
      "Collecting blinker>=1.4\n",
      "  Using cached blinker-1.6.2-py3-none-any.whl (13 kB)\n",
      "Collecting hyperframe>=6.0\n",
      "  Using cached hyperframe-6.0.1-py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: pyOpenSSL>=22.0.0 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from selenium-wire==5.1.0->twitter-scraper-selenium) (23.0.0)\n",
      "Collecting kaitaistruct>=0.7\n",
      "  Using cached kaitaistruct-0.10-py2.py3-none-any.whl (7.0 kB)\n",
      "Collecting h2>=4.0\n",
      "  Using cached h2-4.1.0-py3-none-any.whl (57 kB)\n",
      "Requirement already satisfied: pysocks>=1.7.1 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from selenium-wire==5.1.0->twitter-scraper-selenium) (1.7.1)\n",
      "Requirement already satisfied: pyasn1>=0.3.1 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from selenium-wire==5.1.0->twitter-scraper-selenium) (0.4.8)\n",
      "Collecting wsproto>=0.14\n",
      "  Using cached wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: pyparsing>=2.4.2 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from selenium-wire==5.1.0->twitter-scraper-selenium) (3.0.9)\n",
      "Collecting configparser\n",
      "  Using cached configparser-6.0.0-py3-none-any.whl (19 kB)\n",
      "Collecting crayons\n",
      "  Using cached crayons-0.4.0-py2.py3-none-any.whl (4.6 kB)\n",
      "Collecting hpack<5,>=4.0\n",
      "  Using cached hpack-4.0.0-py3-none-any.whl (32 kB)\n",
      "Requirement already satisfied: cryptography<40,>=38.0.0 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from pyOpenSSL>=22.0.0->selenium-wire==5.1.0->twitter-scraper-selenium) (39.0.1)\n",
      "Requirement already satisfied: sniffio in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium==4.7.0->twitter-scraper-selenium) (1.2.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium==4.7.0->twitter-scraper-selenium) (2.4.0)\n",
      "Collecting outcome\n",
      "  Using cached outcome-1.2.0-py2.py3-none-any.whl (9.7 kB)\n",
      "Collecting exceptiongroup>=1.0.0rc9\n",
      "  Using cached exceptiongroup-1.1.3-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium==4.7.0->twitter-scraper-selenium) (1.15.1)\n",
      "Requirement already satisfied: attrs>=20.1.0 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium==4.7.0->twitter-scraper-selenium) (22.1.0)\n",
      "Collecting h11<1,>=0.9.0\n",
      "  Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from bs4->fake-headers==1.0.2->twitter-scraper-selenium) (4.11.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from crayons->webdriver-manager==3.2.2->twitter-scraper-selenium) (0.4.6)\n",
      "Requirement already satisfied: webencodings in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from html5lib->fake-headers==1.0.2->twitter-scraper-selenium) (0.5.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium==4.7.0->twitter-scraper-selenium) (2.21)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from beautifulsoup4->bs4->fake-headers==1.0.2->twitter-scraper-selenium) (2.3.2.post1)\n",
      "Building wheels for collected packages: bs4\n",
      "  Building wheel for bs4 (setup.py): started\n",
      "  Building wheel for bs4 (setup.py): finished with status 'done'\n",
      "  Created wheel for bs4: filename=bs4-0.0.1-py3-none-any.whl size=1264 sha256=fff87a3f11ea2b6758b42c8863faf51eccbb0a4aa06257e804db80d36d38c5ae\n",
      "  Stored in directory: c:\\users\\eyawo\\appdata\\local\\pip\\cache\\wheels\\e4\\62\\1d\\d4d1bc4f33350ff84227f89b258edb552d604138e3739f5c83\n",
      "Successfully built bs4\n",
      "Installing collected packages: pydivert, brotli, outcome, kaitaistruct, hyperframe, html5lib, hpack, h11, exceptiongroup, crayons, configparser, blinker, wsproto, webdriver-manager, trio, h2, bs4, trio-websocket, fake-headers, selenium, selenium-wire, twitter-scraper-selenium\n",
      "Successfully installed blinker-1.6.2 brotli-1.0.9 bs4-0.0.1 configparser-6.0.0 crayons-0.4.0 exceptiongroup-1.1.3 fake-headers-1.0.2 h11-0.14.0 h2-4.1.0 hpack-4.0.0 html5lib-1.1 hyperframe-6.0.1 kaitaistruct-0.10 outcome-1.2.0 pydivert-2.1.0 selenium-4.7.0 selenium-wire-5.1.0 trio-0.22.2 trio-websocket-0.10.3 twitter-scraper-selenium-5.0.0 webdriver-manager-3.2.2 wsproto-1.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install twitter-scraper-selenium\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e74e1b82-952e-4e05-ae8a-593d5a20ef07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: twitter-scraper-selenium in c:\\users\\eyawo\\appdata\\roaming\\python\\python311\\site-packages (5.0.0)\n",
      "Requirement already satisfied: python-dateutil==2.8.2 in c:\\users\\eyawo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from twitter-scraper-selenium) (2.8.2)\n",
      "Requirement already satisfied: selenium==4.7.0 in c:\\users\\eyawo\\appdata\\roaming\\python\\python311\\site-packages (from twitter-scraper-selenium) (4.7.0)\n",
      "Requirement already satisfied: selenium-wire==5.1.0 in c:\\users\\eyawo\\appdata\\roaming\\python\\python311\\site-packages (from twitter-scraper-selenium) (5.1.0)\n",
      "Requirement already satisfied: webdriver-manager==3.2.2 in c:\\users\\eyawo\\appdata\\roaming\\python\\python311\\site-packages (from twitter-scraper-selenium) (3.2.2)\n",
      "Requirement already satisfied: fake-headers==1.0.2 in c:\\users\\eyawo\\appdata\\roaming\\python\\python311\\site-packages (from twitter-scraper-selenium) (1.0.2)\n",
      "Requirement already satisfied: requests==2.27.1 in c:\\users\\eyawo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from twitter-scraper-selenium) (2.27.1)\n",
      "Requirement already satisfied: bs4 in c:\\users\\eyawo\\appdata\\roaming\\python\\python311\\site-packages (from fake-headers==1.0.2->twitter-scraper-selenium) (0.0.1)\n",
      "Requirement already satisfied: html5lib in c:\\users\\eyawo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from fake-headers==1.0.2->twitter-scraper-selenium) (1.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\eyawo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil==2.8.2->twitter-scraper-selenium) (1.16.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\eyawo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests==2.27.1->twitter-scraper-selenium) (1.25.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\eyawo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests==2.27.1->twitter-scraper-selenium) (2023.7.22)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\eyawo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests==2.27.1->twitter-scraper-selenium) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\eyawo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests==2.27.1->twitter-scraper-selenium) (2.10)\n",
      "Collecting urllib3[socks]~=1.26 (from selenium==4.7.0->twitter-scraper-selenium)\n",
      "  Obtaining dependency information for urllib3[socks]~=1.26 from https://files.pythonhosted.org/packages/c5/05/c214b32d21c0b465506f95c4f28ccbcba15022e000b043b72b3df7728471/urllib3-1.26.16-py2.py3-none-any.whl.metadata\n",
      "  Using cached urllib3-1.26.16-py2.py3-none-any.whl.metadata (48 kB)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\eyawo\\appdata\\roaming\\python\\python311\\site-packages (from selenium==4.7.0->twitter-scraper-selenium) (0.22.2)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\eyawo\\appdata\\roaming\\python\\python311\\site-packages (from selenium==4.7.0->twitter-scraper-selenium) (0.10.3)\n",
      "Requirement already satisfied: blinker>=1.4 in c:\\users\\eyawo\\appdata\\roaming\\python\\python311\\site-packages (from selenium-wire==5.1.0->twitter-scraper-selenium) (1.6.2)\n",
      "Requirement already satisfied: brotli>=1.0.9 in c:\\users\\eyawo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from selenium-wire==5.1.0->twitter-scraper-selenium) (1.0.9)\n",
      "Requirement already satisfied: kaitaistruct>=0.7 in c:\\users\\eyawo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from selenium-wire==5.1.0->twitter-scraper-selenium) (0.10)\n",
      "Requirement already satisfied: pyasn1>=0.3.1 in c:\\users\\eyawo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from selenium-wire==5.1.0->twitter-scraper-selenium) (0.5.0)\n",
      "Requirement already satisfied: pyOpenSSL>=22.0.0 in c:\\users\\eyawo\\appdata\\roaming\\python\\python311\\site-packages (from selenium-wire==5.1.0->twitter-scraper-selenium) (23.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.4.2 in c:\\users\\eyawo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from selenium-wire==5.1.0->twitter-scraper-selenium) (3.1.1)\n",
      "Requirement already satisfied: pysocks>=1.7.1 in c:\\users\\eyawo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from selenium-wire==5.1.0->twitter-scraper-selenium) (1.7.1)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\eyawo\\appdata\\roaming\\python\\python311\\site-packages (from selenium-wire==5.1.0->twitter-scraper-selenium) (1.2.0)\n",
      "Requirement already satisfied: zstandard>=0.14.1 in c:\\users\\eyawo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from selenium-wire==5.1.0->twitter-scraper-selenium) (0.21.0)\n",
      "Requirement already satisfied: h2>=4.0 in c:\\users\\eyawo\\appdata\\roaming\\python\\python311\\site-packages (from selenium-wire==5.1.0->twitter-scraper-selenium) (4.1.0)\n",
      "Requirement already satisfied: hyperframe>=6.0 in c:\\users\\eyawo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from selenium-wire==5.1.0->twitter-scraper-selenium) (6.0.1)\n",
      "Requirement already satisfied: pydivert>=2.0.3 in c:\\users\\eyawo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from selenium-wire==5.1.0->twitter-scraper-selenium) (2.1.0)\n",
      "Requirement already satisfied: configparser in c:\\users\\eyawo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from webdriver-manager==3.2.2->twitter-scraper-selenium) (6.0.0)\n",
      "Requirement already satisfied: crayons in c:\\users\\eyawo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from webdriver-manager==3.2.2->twitter-scraper-selenium) (0.4.0)\n",
      "Requirement already satisfied: hpack<5,>=4.0 in c:\\users\\eyawo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from h2>=4.0->selenium-wire==5.1.0->twitter-scraper-selenium) (4.0.0)\n",
      "Requirement already satisfied: cryptography!=40.0.0,!=40.0.1,<42,>=38.0.0 in c:\\users\\eyawo\\appdata\\roaming\\python\\python311\\site-packages (from pyOpenSSL>=22.0.0->selenium-wire==5.1.0->twitter-scraper-selenium) (41.0.3)\n",
      "Requirement already satisfied: attrs>=20.1.0 in c:\\users\\eyawo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from trio~=0.17->selenium==4.7.0->twitter-scraper-selenium) (23.1.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\eyawo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from trio~=0.17->selenium==4.7.0->twitter-scraper-selenium) (2.4.0)\n",
      "Requirement already satisfied: outcome in c:\\users\\eyawo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from trio~=0.17->selenium==4.7.0->twitter-scraper-selenium) (1.2.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\eyawo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from trio~=0.17->selenium==4.7.0->twitter-scraper-selenium) (1.3.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\eyawo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from trio~=0.17->selenium==4.7.0->twitter-scraper-selenium) (1.15.1)\n",
      "Requirement already satisfied: exceptiongroup in c:\\users\\eyawo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from trio-websocket~=0.9->selenium==4.7.0->twitter-scraper-selenium) (1.1.3)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\eyawo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from wsproto>=0.14->selenium-wire==5.1.0->twitter-scraper-selenium) (0.14.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\eyawo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from bs4->fake-headers==1.0.2->twitter-scraper-selenium) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\eyawo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from crayons->webdriver-manager==3.2.2->twitter-scraper-selenium) (0.4.6)\n",
      "Requirement already satisfied: webencodings in c:\\users\\eyawo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from html5lib->fake-headers==1.0.2->twitter-scraper-selenium) (0.5.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\eyawo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium==4.7.0->twitter-scraper-selenium) (2.21)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\eyawo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from beautifulsoup4->bs4->fake-headers==1.0.2->twitter-scraper-selenium) (2.4.1)\n",
      "Using cached urllib3-1.26.16-py2.py3-none-any.whl (143 kB)\n",
      "Installing collected packages: urllib3\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.25.11\n",
      "    Uninstalling urllib3-1.25.11:\n",
      "      Successfully uninstalled urllib3-1.25.11\n",
      "Successfully installed urllib3-1.26.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: Loading egg at c:\\users\\eyawo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages\\foobar-1.0-py3.11.egg is deprecated. pip 23.3 will enforce this behaviour change. A possible replacement is to use pip for package installation..\n"
     ]
    }
   ],
   "source": [
    "!pip install twitter-scraper-selenium\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a40d3531-5548-47e5-85f1-df7c4684632f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (4.7.0)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from selenium) (2023.7.22)\n",
      "Requirement already satisfied: urllib3[socks]~=1.26 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from selenium) (1.26.14)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from selenium) (0.22.2)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from selenium) (0.10.3)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.1)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: outcome in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: attrs>=20.1.0 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (22.1.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: idna in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.4)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.1.3)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from urllib3[socks]~=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c97e015c-c26f-4864-8e2d-e8c211cca171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\eyawo\\appdata\\roaming\\python\\python311\\site-packages (4.7.0)\n",
      "Requirement already satisfied: urllib3[socks]~=1.26 in c:\\users\\eyawo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from selenium) (1.26.16)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\eyawo\\appdata\\roaming\\python\\python311\\site-packages (from selenium) (0.22.2)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\eyawo\\appdata\\roaming\\python\\python311\\site-packages (from selenium) (0.10.3)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\eyawo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from selenium) (2023.7.22)\n",
      "Requirement already satisfied: attrs>=20.1.0 in c:\\users\\eyawo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from trio~=0.17->selenium) (23.1.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\eyawo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\eyawo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from trio~=0.17->selenium) (2.10)\n",
      "Requirement already satisfied: outcome in c:\\users\\eyawo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\eyawo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\eyawo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from trio~=0.17->selenium) (1.15.1)\n",
      "Requirement already satisfied: exceptiongroup in c:\\users\\eyawo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.1.3)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\eyawo\\appdata\\roaming\\python\\python311\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\eyawo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from urllib3[socks]~=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\eyawo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\eyawo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: Loading egg at c:\\users\\eyawo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages\\foobar-1.0-py3.11.egg is deprecated. pip 23.3 will enforce this behaviour change. A possible replacement is to use pip for package installation..\n"
     ]
    }
   ],
   "source": [
    "pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2203e9bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: twitter-scraper-selenium in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (5.0.0)\n",
      "Requirement already satisfied: selenium-wire==5.1.0 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from twitter-scraper-selenium) (5.1.0)\n",
      "Requirement already satisfied: fake-headers==1.0.2 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from twitter-scraper-selenium) (1.0.2)\n",
      "Requirement already satisfied: selenium==4.7.0 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from twitter-scraper-selenium) (4.7.0)\n",
      "Requirement already satisfied: requests==2.27.1 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from twitter-scraper-selenium) (2.27.1)\n",
      "Requirement already satisfied: webdriver-manager==3.2.2 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from twitter-scraper-selenium) (3.2.2)\n",
      "Requirement already satisfied: python-dateutil==2.8.2 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from twitter-scraper-selenium) (2.8.2)\n",
      "Requirement already satisfied: html5lib in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from fake-headers==1.0.2->twitter-scraper-selenium) (1.1)\n",
      "Requirement already satisfied: bs4 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from fake-headers==1.0.2->twitter-scraper-selenium) (0.0.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from python-dateutil==2.8.2->twitter-scraper-selenium) (1.16.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from requests==2.27.1->twitter-scraper-selenium) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from requests==2.27.1->twitter-scraper-selenium) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from requests==2.27.1->twitter-scraper-selenium) (2023.7.22)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from requests==2.27.1->twitter-scraper-selenium) (2.0.4)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from selenium==4.7.0->twitter-scraper-selenium) (0.10.3)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from selenium==4.7.0->twitter-scraper-selenium) (0.22.2)\n",
      "Requirement already satisfied: h2>=4.0 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from selenium-wire==5.1.0->twitter-scraper-selenium) (4.1.0)\n",
      "Requirement already satisfied: pysocks>=1.7.1 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from selenium-wire==5.1.0->twitter-scraper-selenium) (1.7.1)\n",
      "Requirement already satisfied: pyasn1>=0.3.1 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from selenium-wire==5.1.0->twitter-scraper-selenium) (0.4.8)\n",
      "Requirement already satisfied: hyperframe>=6.0 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from selenium-wire==5.1.0->twitter-scraper-selenium) (6.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.4.2 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from selenium-wire==5.1.0->twitter-scraper-selenium) (3.0.9)\n",
      "Requirement already satisfied: zstandard>=0.14.1 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from selenium-wire==5.1.0->twitter-scraper-selenium) (0.19.0)\n",
      "Requirement already satisfied: brotli>=1.0.9 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from selenium-wire==5.1.0->twitter-scraper-selenium) (1.0.9)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from selenium-wire==5.1.0->twitter-scraper-selenium) (1.2.0)\n",
      "Requirement already satisfied: pydivert>=2.0.3 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from selenium-wire==5.1.0->twitter-scraper-selenium) (2.1.0)\n",
      "Requirement already satisfied: blinker>=1.4 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from selenium-wire==5.1.0->twitter-scraper-selenium) (1.6.2)\n",
      "Requirement already satisfied: pyOpenSSL>=22.0.0 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from selenium-wire==5.1.0->twitter-scraper-selenium) (23.0.0)\n",
      "Requirement already satisfied: kaitaistruct>=0.7 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from selenium-wire==5.1.0->twitter-scraper-selenium) (0.10)\n",
      "Requirement already satisfied: crayons in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from webdriver-manager==3.2.2->twitter-scraper-selenium) (0.4.0)\n",
      "Requirement already satisfied: configparser in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from webdriver-manager==3.2.2->twitter-scraper-selenium) (6.0.0)\n",
      "Requirement already satisfied: hpack<5,>=4.0 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from h2>=4.0->selenium-wire==5.1.0->twitter-scraper-selenium) (4.0.0)\n",
      "Requirement already satisfied: cryptography<40,>=38.0.0 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from pyOpenSSL>=22.0.0->selenium-wire==5.1.0->twitter-scraper-selenium) (39.0.1)\n",
      "Requirement already satisfied: outcome in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium==4.7.0->twitter-scraper-selenium) (1.2.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium==4.7.0->twitter-scraper-selenium) (1.15.1)\n",
      "Requirement already satisfied: attrs>=20.1.0 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium==4.7.0->twitter-scraper-selenium) (22.1.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium==4.7.0->twitter-scraper-selenium) (2.4.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium==4.7.0->twitter-scraper-selenium) (1.2.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium==4.7.0->twitter-scraper-selenium) (1.1.3)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from wsproto>=0.14->selenium-wire==5.1.0->twitter-scraper-selenium) (0.14.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from bs4->fake-headers==1.0.2->twitter-scraper-selenium) (4.11.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from crayons->webdriver-manager==3.2.2->twitter-scraper-selenium) (0.4.6)\n",
      "Requirement already satisfied: webencodings in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from html5lib->fake-headers==1.0.2->twitter-scraper-selenium) (0.5.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium==4.7.0->twitter-scraper-selenium) (2.21)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from beautifulsoup4->bs4->fake-headers==1.0.2->twitter-scraper-selenium) (2.3.2.post1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade twitter-scraper-selenium\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de075023-930a-4952-8fc5-1894de188e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-15 17:18:14,751 - twitter_scraper_selenium.keyword_api - WARNING - Failed to make request!\n"
     ]
    }
   ],
   "source": [
    "from twitter_scraper_selenium import scrape_keyword_with_api\n",
    "import time\n",
    "\n",
    "query = \"#US\"\n",
    "tweets_count = 10\n",
    "output_filename = \"Tunisia\"\n",
    "retry_attempts = 3\n",
    "\n",
    "for attempt in range(retry_attempts):\n",
    "    try:\n",
    "        scrape_keyword_with_api(query=query, tweets_count=tweets_count, output_filename=output_filename)\n",
    "        break  # Break the loop if the request was successful\n",
    "    except Exception as e:\n",
    "        print(f\"Attempt {attempt+1} failed: {str(e)}\")\n",
    "        if attempt < retry_attempts - 1:\n",
    "            print(\"Retrying after 5 seconds...\")\n",
    "            time.sleep(5)  # Wait for 5 seconds before retrying\n",
    "        else:\n",
    "            print(\"Maximum retry attempts reached.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237825f3",
   "metadata": {},
   "source": [
    "# tweeter streaming "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1ccf71b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tweepy in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (4.14.0)\n",
      "Requirement already satisfied: oauthlib<4,>=3.2.0 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from tweepy) (3.2.2)\n",
      "Requirement already satisfied: requests-oauthlib<2,>=1.2.0 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from tweepy) (1.3.1)\n",
      "Requirement already satisfied: requests<3,>=2.27.0 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from tweepy) (2.27.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from requests<3,>=2.27.0->tweepy) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from requests<3,>=2.27.0->tweepy) (2023.7.22)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from requests<3,>=2.27.0->tweepy) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from requests<3,>=2.27.0->tweepy) (1.26.14)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade tweepy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58b544f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-15 19:01:26,496 - twitter_scraper_selenium.keyword_api - WARNING - Failed to make request!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from twitter_scraper_selenium import scrape_keyword_with_api\n",
    "\n",
    "query = \"#Tunisia\"\n",
    "tweets_count = 10\n",
    "output_filename = \"Tn\"\n",
    "scrape_keyword_with_api(query=query, tweets_count=tweets_count, output_filename=output_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4bbd836a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting webdriver-manager==3.2.2\n",
      "  Using cached webdriver_manager-3.2.2-py2.py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from webdriver-manager==3.2.2) (2.27.1)\n",
      "Requirement already satisfied: crayons in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from webdriver-manager==3.2.2) (0.4.0)\n",
      "Requirement already satisfied: configparser in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from webdriver-manager==3.2.2) (6.0.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from crayons->webdriver-manager==3.2.2) (0.4.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from requests->webdriver-manager==3.2.2) (2023.7.22)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from requests->webdriver-manager==3.2.2) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from requests->webdriver-manager==3.2.2) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from requests->webdriver-manager==3.2.2) (1.26.14)\n",
      "Installing collected packages: webdriver-manager\n",
      "  Attempting uninstall: webdriver-manager\n",
      "    Found existing installation: webdriver-manager 4.0.0\n",
      "    Uninstalling webdriver-manager-4.0.0:\n",
      "      Successfully uninstalled webdriver-manager-4.0.0\n",
      "Successfully installed webdriver-manager-3.2.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install webdriver-manager==3.2.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "66992850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: webdriver-manager in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (3.2.2)\n",
      "Requirement already satisfied: requests in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from webdriver-manager) (2.27.1)\n",
      "Requirement already satisfied: crayons in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from webdriver-manager) (0.4.0)\n",
      "Requirement already satisfied: configparser in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from webdriver-manager) (6.0.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from crayons->webdriver-manager) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (2023.7.22)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install webdriver-manager\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbdfd9e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - Current google-chrome version is 115.0.5790\n",
      "[WDM] - Driver [C:\\Users\\eyawo\\.wdm\\drivers\\chromedriver\\win32\\114.0.5735.90\\chromedriver.exe] found in cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "chrome_options.add_argument(\"--headless\")  # Optional: Run in headless mode\n",
    "\n",
    "driver_path = ChromeDriverManager(version=\"114.0.5735.90\").install()\n",
    "driver = webdriver.Chrome(service=webdriver.chrome.service.Service(driver_path), options=chrome_options)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "454759ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - Current google-chrome version is 115.0.5790\n",
      "[WDM] - Driver [C:\\Users\\eyawo\\.wdm\\drivers\\chromedriver\\win32\\114.0.5735.90\\chromedriver.exe] found in cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eyawo\\AppData\\Local\\Temp\\ipykernel_12568\\2174534070.py:11: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(executable_path=driver_path, options=chrome_options)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'close'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\twitter_scraper_selenium\\keyword.py:126\u001b[0m, in \u001b[0;36mKeyword.scrap\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 126\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_driver\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    127\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdriver\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mURL)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\twitter_scraper_selenium\\keyword.py:50\u001b[0m, in \u001b[0;36mKeyword.start_driver\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;124;03m\"\"\"changes the class member driver value to driver on call\"\"\"\u001b[39;00m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdriver \u001b[38;5;241m=\u001b[39m \u001b[43mInitializer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m---> 50\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbrowser\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheadless\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproxy\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\twitter_scraper_selenium\\driver_initialization.py:94\u001b[0m, in \u001b[0;36mInitializer.init\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;124;03m\"\"\"returns driver instance\"\"\"\u001b[39;00m\n\u001b[1;32m---> 94\u001b[0m driver \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_driver_for_browser\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbrowser_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m driver\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\twitter_scraper_selenium\\driver_initialization.py:57\u001b[0m, in \u001b[0;36mInitializer.set_driver_for_browser\u001b[1;34m(self, browser_name)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# if browser is suppose to be chrome\u001b[39;00m\n\u001b[1;32m---> 57\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mbrowser_name\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchrome\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     58\u001b[0m     browser_option \u001b[38;5;241m=\u001b[39m CustomChromeOptions()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'WebDriver' object has no attribute 'lower'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m driver \u001b[38;5;241m=\u001b[39m webdriver\u001b[38;5;241m.\u001b[39mChrome(executable_path\u001b[38;5;241m=\u001b[39mdriver_path, options\u001b[38;5;241m=\u001b[39mchrome_options)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Make sure to use the browser instance, not its name\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m \u001b[43mscrape_keyword\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeyword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtunisia\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbrowser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdriver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Use the driver instance directly\u001b[39;49;00m\n\u001b[0;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtweets_count\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43muntil\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m2023-08-01\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43msince\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m2023-08-04\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m     22\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Close the driver after scraping\u001b[39;00m\n\u001b[0;32m     25\u001b[0m driver\u001b[38;5;241m.\u001b[39mquit()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\twitter_scraper_selenium\\keyword.py:215\u001b[0m, in \u001b[0;36mscrape_keyword\u001b[1;34m(keyword, browser, until, since, since_id, max_id, within_time, proxy, tweets_count, output_format, filename, directory, headless)\u001b[0m\n\u001b[0;32m    211\u001b[0m URL \u001b[38;5;241m=\u001b[39m Scraping_utilities\u001b[38;5;241m.\u001b[39murl_generator(keyword, since\u001b[38;5;241m=\u001b[39msince, until\u001b[38;5;241m=\u001b[39muntil,\n\u001b[0;32m    212\u001b[0m                                        since_id\u001b[38;5;241m=\u001b[39msince_id, max_id\u001b[38;5;241m=\u001b[39mmax_id, within_time\u001b[38;5;241m=\u001b[39mwithin_time)\n\u001b[0;32m    213\u001b[0m keyword_bot \u001b[38;5;241m=\u001b[39m Keyword(keyword, browser\u001b[38;5;241m=\u001b[39mbrowser, url\u001b[38;5;241m=\u001b[39mURL,\n\u001b[0;32m    214\u001b[0m                       proxy\u001b[38;5;241m=\u001b[39mproxy, tweets_count\u001b[38;5;241m=\u001b[39mtweets_count, headless\u001b[38;5;241m=\u001b[39mheadless)\n\u001b[1;32m--> 215\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mkeyword_bot\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscrap\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_format\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjson\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m filename \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    218\u001b[0m       \u001b[38;5;66;03m# if filename was not provided then print the JSON to console\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\twitter_scraper_selenium\\keyword.py:138\u001b[0m, in \u001b[0;36mKeyword.scrap\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m data\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[1;32m--> 138\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclose_driver\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    139\u001b[0m     logger\u001b[38;5;241m.\u001b[39mexception(\n\u001b[0;32m    140\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError at method scrap on : \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(ex))\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\twitter_scraper_selenium\\keyword.py:53\u001b[0m, in \u001b[0;36mKeyword.close_driver\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclose_driver\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m---> 53\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclose\u001b[49m()\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdriver\u001b[38;5;241m.\u001b[39mquit()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'close'"
     ]
    }
   ],
   "source": [
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium import webdriver\n",
    "from twitter_scraper_selenium import scrape_keyword\n",
    "\n",
    "chrome_driver_version = \"114.0.5735.90\"  # Replace with your ChromeDriver version\n",
    "driver_path = ChromeDriverManager(version=chrome_driver_version).install()\n",
    "\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "chrome_options.add_argument(\"--headless\")\n",
    "\n",
    "driver = webdriver.Chrome(executable_path=driver_path, options=chrome_options)\n",
    "\n",
    "# Make sure to use the browser instance, not its name\n",
    "scrape_keyword(\n",
    "    keyword=\"tunisia\",\n",
    "    browser=driver,  # Use the driver instance directly\n",
    "    tweets_count=10,\n",
    "    until=\"2023-08-01\",\n",
    "    since=\"2023-08-04\",\n",
    "    output_format=\"csv\",\n",
    "    filename=\"tn\"\n",
    ")\n",
    "\n",
    "# Close the driver after scraping\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bfec4012",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tweepy' has no attribute 'Stream'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m api \u001b[38;5;241m=\u001b[39m tweepy\u001b[38;5;241m.\u001b[39mAPI(auth)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Create a custom StreamListener\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mMyStreamListener\u001b[39;00m(\u001b[43mtweepy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mStream\u001b[49m):\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_status\u001b[39m(\u001b[38;5;28mself\u001b[39m, status):\n\u001b[0;32m     19\u001b[0m         \u001b[38;5;28mprint\u001b[39m(status\u001b[38;5;241m.\u001b[39mtext)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tweepy' has no attribute 'Stream'"
     ]
    }
   ],
   "source": [
    "\n",
    "import tweepy\n",
    "from tweepy.auth import OAuthHandler\n",
    "\n",
    "# Set your Twitter API credentials\n",
    "consumer_key = \"F0iQh78LQ7i1XMD6hJ7uTOBew\"\n",
    "consumer_secret = \"u2Wn7BoxlXyWslv8amHCiiDLDlk51MEOydxw4FfUsBpMRSOBZ3\"\n",
    "access_token = \"1636765367451230209-HKRjedpRK34DEyc3U4Muw8dMjrrXTH\"\n",
    "access_token_secret = \"d9iCix5JoUeDtwV2dhMtNEw0mLIxl7PxfasydJzbrIE1l\"\n",
    "# Authenticate to the Twitter API\n",
    "auth = OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "\n",
    "# Create a Tweepy API object\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "# Create a custom StreamListener\n",
    "class MyStreamListener(tweepy.Stream):\n",
    "    def on_status(self, status):\n",
    "        print(status.text)\n",
    "\n",
    "# Create a Stream object using your API credentials and the custom StreamListener\n",
    "my_stream_listener = MyStreamListener(auth=auth)\n",
    "my_stream_listener.filter(track=['tunisia', 'news'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77270380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tweepy in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (4.14.0)\n",
      "Requirement already satisfied: requests<3,>=2.27.0 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from tweepy) (2.27.1)\n",
      "Requirement already satisfied: oauthlib<4,>=3.2.0 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from tweepy) (3.2.2)\n",
      "Requirement already satisfied: requests-oauthlib<2,>=1.2.0 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from tweepy) (1.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from requests<3,>=2.27.0->tweepy) (3.4)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from requests<3,>=2.27.0->tweepy) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from requests<3,>=2.27.0->tweepy) (2023.7.22)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from requests<3,>=2.27.0->tweepy) (1.26.14)\n",
      "Requirement already satisfied: selenium in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (4.7.0)\n",
      "Requirement already satisfied: urllib3[socks]~=1.26 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from selenium) (1.26.14)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from selenium) (0.10.3)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from selenium) (0.22.2)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from selenium) (2023.7.22)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.1.3)\n",
      "Requirement already satisfied: idna in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.4)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: outcome in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: attrs>=20.1.0 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (22.1.0)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from urllib3[socks]~=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tweepy\n",
    "!pip install selenium\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a664dddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f9e32980",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eyawo\\AppData\\Local\\Temp\\ipykernel_4740\\560051099.py:23: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Firefox(executable_path=firefox_driver_path, options=options)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'WebDriver' object has no attribute 'find_element_by_tag_name'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 46\u001b[0m\n\u001b[0;32m     44\u001b[0m keyword \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtunisia\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     45\u001b[0m tweet_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m50\u001b[39m\n\u001b[1;32m---> 46\u001b[0m tweets \u001b[38;5;241m=\u001b[39m \u001b[43mscrape_tweets_by_keyword\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyword\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtweet_count\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m# Display the scraped tweets\u001b[39;00m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, tweet \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tweets, start\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n",
      "Cell \u001b[1;32mIn[21], line 29\u001b[0m, in \u001b[0;36mscrape_tweets_by_keyword\u001b[1;34m(keyword, count)\u001b[0m\n\u001b[0;32m     26\u001b[0m driver\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://twitter.com/search?q=\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m keyword \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m&src=typed_query\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     27\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m5\u001b[39m)  \u001b[38;5;66;03m# Allow the page to load\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m body \u001b[38;5;241m=\u001b[39m \u001b[43mdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_element_by_tag_name\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbody\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(count \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m10\u001b[39m):\n\u001b[0;32m     32\u001b[0m     body\u001b[38;5;241m.\u001b[39msend_keys(Keys\u001b[38;5;241m.\u001b[39mPAGE_DOWN)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'WebDriver' object has no attribute 'find_element_by_tag_name'"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import tweepy\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "consumer_key = \"F0iQh78LQ7i1XMD6hJ7uTOBew\"\n",
    "consumer_secret = \"u2Wn7BoxlXyWslv8amHCiiDLDlk51MEOydxw4FfUsBpMRSOBZ3\"\n",
    "access_token = \"1636765367451230209-HKRjedpRK34DEyc3U4Muw8dMjrrXTH\"\n",
    "access_token_secret = \"d9iCix5JoUeDtwV2dhMtNEw0mLIxl7PxfasydJzbrIE1l\"\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True)\n",
    "\n",
    "# Set up Firefox WebDriver\n",
    "firefox_driver_path = \"C:/Users/eyawo/Downloads/geckodriver.exe\"\n",
    "firefox_binary_path = \"C:/Program Files/Mozilla Firefox/firefox.exe\"  # Update with the correct path\n",
    "\n",
    "# Create Firefox WebDriver instance\n",
    "options = webdriver.FirefoxOptions()\n",
    "options.binary_location = firefox_binary_path\n",
    "driver = webdriver.Firefox(executable_path=firefox_driver_path, options=options)\n",
    "\n",
    "def scrape_tweets_by_keyword(keyword, count):\n",
    "    driver.get(\"https://twitter.com/search?q=\" + keyword + \"&src=typed_query\")\n",
    "    time.sleep(5)  # Allow the page to load\n",
    "\n",
    "    body = driver.find_element_by_tag_name(\"body\")\n",
    "\n",
    "    for _ in range(count // 10):\n",
    "        body.send_keys(Keys.PAGE_DOWN)\n",
    "        time.sleep(10)  # Wait for scrolling to take effect\n",
    "\n",
    "    tweet_elements = driver.find_elements_by_css_selector(\"div[data-testid='tweet']\")\n",
    "    \n",
    "    tweets = []\n",
    "    for tweet_element in tweet_elements:\n",
    "        tweet_text = tweet_element.find_element_by_css_selector(\"div[data-testid='tweet'] div[dir='auto']\").text\n",
    "        tweets.append(tweet_text)\n",
    "    \n",
    "    return tweets\n",
    "\n",
    "keyword = \"tunisia\"\n",
    "tweet_count = 50\n",
    "tweets = scrape_tweets_by_keyword(keyword, tweet_count)\n",
    "\n",
    "# Display the scraped tweets\n",
    "for i, tweet in enumerate(tweets, start=1):\n",
    "    print(f\"Tweet {i}: {tweet}\\n\")\n",
    "\n",
    "# Close the Firefox WebDriver\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8644e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "consumer_key = \"F0iQh78LQ7i1XMD6hJ7uTOBew\"\n",
    "consumer_secret = \"u2Wn7BoxlXyWslv8amHCiiDLDlk51MEOydxw4FfUsBpMRSOBZ3\"\n",
    "access_token = \"1636765367451230209-HKRjedpRK34DEyc3U4Muw8dMjrrXTH\"\n",
    "access_token_secret = \"d9iCix5JoUeDtwV2dhMtNEw0mLIxl7PxfasydJzbrIE1l\"\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8e2103",
   "metadata": {},
   "outputs": [],
   "source": [
    "firefox_driver_path = \"PATH_TO_FIREFOX_DRIVER\"\n",
    "driver = webdriver.Firefox(executable_path=firefox_driver_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e16df4f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: twitter_scraper_selenium in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (5.0.0)\n",
      "Requirement already satisfied: fake-headers==1.0.2 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from twitter_scraper_selenium) (1.0.2)\n",
      "Requirement already satisfied: selenium-wire==5.1.0 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from twitter_scraper_selenium) (5.1.0)\n",
      "Requirement already satisfied: python-dateutil==2.8.2 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from twitter_scraper_selenium) (2.8.2)\n",
      "Requirement already satisfied: webdriver-manager==3.2.2 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from twitter_scraper_selenium) (3.2.2)\n",
      "Requirement already satisfied: selenium==4.7.0 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from twitter_scraper_selenium) (4.7.0)\n",
      "Requirement already satisfied: requests==2.27.1 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from twitter_scraper_selenium) (2.27.1)\n",
      "Requirement already satisfied: bs4 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from fake-headers==1.0.2->twitter_scraper_selenium) (0.0.1)\n",
      "Requirement already satisfied: html5lib in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from fake-headers==1.0.2->twitter_scraper_selenium) (1.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from python-dateutil==2.8.2->twitter_scraper_selenium) (1.16.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from requests==2.27.1->twitter_scraper_selenium) (3.4)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from requests==2.27.1->twitter_scraper_selenium) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from requests==2.27.1->twitter_scraper_selenium) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from requests==2.27.1->twitter_scraper_selenium) (2023.7.22)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from selenium==4.7.0->twitter_scraper_selenium) (0.10.3)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from selenium==4.7.0->twitter_scraper_selenium) (0.22.2)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from selenium-wire==5.1.0->twitter_scraper_selenium) (1.2.0)\n",
      "Requirement already satisfied: pysocks>=1.7.1 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from selenium-wire==5.1.0->twitter_scraper_selenium) (1.7.1)\n",
      "Requirement already satisfied: h2>=4.0 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from selenium-wire==5.1.0->twitter_scraper_selenium) (4.1.0)\n",
      "Requirement already satisfied: blinker>=1.4 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from selenium-wire==5.1.0->twitter_scraper_selenium) (1.6.2)\n",
      "Requirement already satisfied: pyOpenSSL>=22.0.0 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from selenium-wire==5.1.0->twitter_scraper_selenium) (23.0.0)\n",
      "Requirement already satisfied: pyasn1>=0.3.1 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from selenium-wire==5.1.0->twitter_scraper_selenium) (0.4.8)\n",
      "Requirement already satisfied: pydivert>=2.0.3 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from selenium-wire==5.1.0->twitter_scraper_selenium) (2.1.0)\n",
      "Requirement already satisfied: brotli>=1.0.9 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from selenium-wire==5.1.0->twitter_scraper_selenium) (1.0.9)\n",
      "Requirement already satisfied: hyperframe>=6.0 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from selenium-wire==5.1.0->twitter_scraper_selenium) (6.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.4.2 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from selenium-wire==5.1.0->twitter_scraper_selenium) (3.0.9)\n",
      "Requirement already satisfied: kaitaistruct>=0.7 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from selenium-wire==5.1.0->twitter_scraper_selenium) (0.10)\n",
      "Requirement already satisfied: zstandard>=0.14.1 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from selenium-wire==5.1.0->twitter_scraper_selenium) (0.19.0)\n",
      "Requirement already satisfied: crayons in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from webdriver-manager==3.2.2->twitter_scraper_selenium) (0.4.0)\n",
      "Requirement already satisfied: configparser in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from webdriver-manager==3.2.2->twitter_scraper_selenium) (6.0.0)\n",
      "Requirement already satisfied: hpack<5,>=4.0 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from h2>=4.0->selenium-wire==5.1.0->twitter_scraper_selenium) (4.0.0)\n",
      "Requirement already satisfied: cryptography<40,>=38.0.0 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from pyOpenSSL>=22.0.0->selenium-wire==5.1.0->twitter_scraper_selenium) (39.0.1)\n",
      "Requirement already satisfied: attrs>=20.1.0 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium==4.7.0->twitter_scraper_selenium) (22.1.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium==4.7.0->twitter_scraper_selenium) (1.2.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium==4.7.0->twitter_scraper_selenium) (2.4.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium==4.7.0->twitter_scraper_selenium) (1.1.3)\n",
      "Requirement already satisfied: outcome in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium==4.7.0->twitter_scraper_selenium) (1.2.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium==4.7.0->twitter_scraper_selenium) (1.15.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from wsproto>=0.14->selenium-wire==5.1.0->twitter_scraper_selenium) (0.14.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from bs4->fake-headers==1.0.2->twitter_scraper_selenium) (4.11.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from crayons->webdriver-manager==3.2.2->twitter_scraper_selenium) (0.4.6)\n",
      "Requirement already satisfied: webencodings in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from html5lib->fake-headers==1.0.2->twitter_scraper_selenium) (0.5.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium==4.7.0->twitter_scraper_selenium) (2.21)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\eyawo\\anaconda3\\lib\\site-packages (from beautifulsoup4->bs4->fake-headers==1.0.2->twitter_scraper_selenium) (2.3.2.post1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade twitter_scraper_selenium\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6b13f548",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eyawo\\AppData\\Local\\Temp\\ipykernel_4740\\3708551902.py:6: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Firefox(executable_path=firefox_driver_path)\n"
     ]
    },
    {
     "ename": "WebDriverException",
     "evalue": "Message: Failed to decode response from marionette\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mWebDriverException\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Scroll to load more tweets using JavaScript\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m):\n\u001b[1;32m---> 13\u001b[0m     \u001b[43mdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_script\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwindow.scrollTo(0, document.body.scrollHeight);\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m20\u001b[39m)  \u001b[38;5;66;03m# Wait for scrolling and tweets to load\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Extract tweet elements and print their text\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:506\u001b[0m, in \u001b[0;36mWebDriver.execute_script\u001b[1;34m(self, script, *args)\u001b[0m\n\u001b[0;32m    503\u001b[0m converted_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(args)\n\u001b[0;32m    504\u001b[0m command \u001b[38;5;241m=\u001b[39m Command\u001b[38;5;241m.\u001b[39mW3C_EXECUTE_SCRIPT\n\u001b[1;32m--> 506\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscript\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscript\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43margs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mconverted_args\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:444\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    442\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    443\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m--> 444\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    445\u001b[0m     response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    446\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:249\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    247\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[1;32m--> 249\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mWebDriverException\u001b[0m: Message: Failed to decode response from marionette\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "import time\n",
    "\n",
    "# Set up Firefox WebDriver\n",
    "firefox_driver_path = \"path_to_geckodriver.exe\"\n",
    "driver = webdriver.Firefox(executable_path=firefox_driver_path)\n",
    "\n",
    "# Navigate to the Twitter search page\n",
    "driver.get(\"https://twitter.com/search?q=%23usa\")\n",
    "\n",
    "# Scroll to load more tweets using JavaScript\n",
    "for _ in range(10):\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(20)  # Wait for scrolling and tweets to load\n",
    "\n",
    "# Extract tweet elements and print their text\n",
    "tweet_elements = driver.find_elements_by_css_selector(\"div[data-testid='tweet']\")\n",
    "for tweet_element in tweet_elements:\n",
    "    tweet_text = tweet_element.text\n",
    "    print(tweet_text)\n",
    "\n",
    "# Close the WebDriver\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c535ac4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - Driver [C:\\Users\\eyawo\\.wdm\\drivers\\geckodriver\\win64\\v0.33.0\\geckodriver.exe] found in cache\n",
      "2023-08-15 21:38:55,961 - twitter_scraper_selenium.driver_utils - ERROR - Tweets did not appear!, Try setting headless=False to see what is happening\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\eyawo\\anaconda3\\lib\\site-packages\\twitter_scraper_selenium\\driver_utils.py\", line 35, in wait_until_tweets_appear\n",
      "    WebDriverWait(driver, 10).until(EC.presence_of_element_located(\n",
      "  File \"C:\\Users\\eyawo\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\support\\wait.py\", line 95, in until\n",
      "    raise TimeoutException(message, screen, stacktrace)\n",
      "selenium.common.exceptions.TimeoutException: Message: \n",
      "Stacktrace:\n",
      "RemoteError@chrome://remote/content/shared/RemoteError.sys.mjs:8:8\n",
      "WebDriverError@chrome://remote/content/shared/webdriver/Errors.sys.mjs:187:5\n",
      "NoSuchElementError@chrome://remote/content/shared/webdriver/Errors.sys.mjs:505:5\n",
      "dom.find/</<@chrome://remote/content/shared/DOM.sys.mjs:132:16\n",
      "\n",
      "2023-08-15 21:39:03,476 - twitter_scraper_selenium.element_finder - ERROR - Error at method find_status : Message: Unable to locate element: a[aria-label][dir]\n",
      "Stacktrace:\n",
      "RemoteError@chrome://remote/content/shared/RemoteError.sys.mjs:8:8\n",
      "WebDriverError@chrome://remote/content/shared/webdriver/Errors.sys.mjs:187:5\n",
      "NoSuchElementError@chrome://remote/content/shared/webdriver/Errors.sys.mjs:505:5\n",
      "dom.find/</<@chrome://remote/content/shared/DOM.sys.mjs:132:16\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\eyawo\\anaconda3\\lib\\site-packages\\twitter_scraper_selenium\\element_finder.py\", line 68, in find_status\n",
      "    anchor = tweet.find_element(\n",
      "  File \"C:\\Users\\eyawo\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py\", line 433, in find_element\n",
      "    return self._execute(Command.FIND_CHILD_ELEMENT, {\"using\": by, \"value\": value})[\"value\"]\n",
      "  File \"C:\\Users\\eyawo\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py\", line 410, in _execute\n",
      "    return self._parent.execute(command, params)\n",
      "  File \"C:\\Users\\eyawo\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\", line 444, in execute\n",
      "    self.error_handler.check_response(response)\n",
      "  File \"C:\\Users\\eyawo\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\", line 249, in check_response\n",
      "    raise exception_class(message, screen, stacktrace)\n",
      "selenium.common.exceptions.NoSuchElementException: Message: Unable to locate element: a[aria-label][dir]\n",
      "Stacktrace:\n",
      "RemoteError@chrome://remote/content/shared/RemoteError.sys.mjs:8:8\n",
      "WebDriverError@chrome://remote/content/shared/webdriver/Errors.sys.mjs:187:5\n",
      "NoSuchElementError@chrome://remote/content/shared/webdriver/Errors.sys.mjs:505:5\n",
      "dom.find/</<@chrome://remote/content/shared/DOM.sys.mjs:132:16\n",
      "\n",
      "2023-08-15 21:39:03,518 - ERROR - Error at method fetch_and_store_data : not enough values to unpack (expected 2, got 0)\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\eyawo\\anaconda3\\lib\\site-packages\\twitter_scraper_selenium\\keyword.py\", line 73, in fetch_and_store_data\n",
      "    status, tweet_url = Finder.find_status(tweet)\n",
      "ValueError: not enough values to unpack (expected 2, got 0)\n"
     ]
    }
   ],
   "source": [
    "from twitter_scraper_selenium import scrape_keyword\n",
    "import pandas as pd\n",
    "\n",
    "# Scrape tweets\n",
    "tweets = scrape_keyword(\n",
    "    keyword=\"#news\",\n",
    "    browser=\"firefox\",\n",
    "    tweets_count=5,\n",
    "    headless=False\n",
    ")\n",
    "\n",
    "# Create a DataFrame with a single column named \"Tweets\" and index\n",
    "df = pd.DataFrame({\"Tweets\": tweets, \"Index\": range(1, len(tweets) + 1)})\n",
    "\n",
    "# Save DataFrame to a CSV file\n",
    "filename = \"news.csv\"\n",
    "df.to_csv(filename, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "af0462d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - Driver [C:\\Users\\eyawo\\.wdm\\drivers\\geckodriver\\win64\\v0.33.0\\geckodriver.exe] found in cache\n",
      "2023-08-15 21:49:32,327 - twitter_scraper_selenium.element_finder - ERROR - Error at method find_status : Message: Unable to locate element: a[aria-label][dir]\n",
      "Stacktrace:\n",
      "RemoteError@chrome://remote/content/shared/RemoteError.sys.mjs:8:8\n",
      "WebDriverError@chrome://remote/content/shared/webdriver/Errors.sys.mjs:187:5\n",
      "NoSuchElementError@chrome://remote/content/shared/webdriver/Errors.sys.mjs:505:5\n",
      "dom.find/</<@chrome://remote/content/shared/DOM.sys.mjs:132:16\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\eyawo\\anaconda3\\lib\\site-packages\\twitter_scraper_selenium\\element_finder.py\", line 68, in find_status\n",
      "    anchor = tweet.find_element(\n",
      "  File \"C:\\Users\\eyawo\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py\", line 433, in find_element\n",
      "    return self._execute(Command.FIND_CHILD_ELEMENT, {\"using\": by, \"value\": value})[\"value\"]\n",
      "  File \"C:\\Users\\eyawo\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py\", line 410, in _execute\n",
      "    return self._parent.execute(command, params)\n",
      "  File \"C:\\Users\\eyawo\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\", line 444, in execute\n",
      "    self.error_handler.check_response(response)\n",
      "  File \"C:\\Users\\eyawo\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\", line 249, in check_response\n",
      "    raise exception_class(message, screen, stacktrace)\n",
      "selenium.common.exceptions.NoSuchElementException: Message: Unable to locate element: a[aria-label][dir]\n",
      "Stacktrace:\n",
      "RemoteError@chrome://remote/content/shared/RemoteError.sys.mjs:8:8\n",
      "WebDriverError@chrome://remote/content/shared/webdriver/Errors.sys.mjs:187:5\n",
      "NoSuchElementError@chrome://remote/content/shared/webdriver/Errors.sys.mjs:505:5\n",
      "dom.find/</<@chrome://remote/content/shared/DOM.sys.mjs:132:16\n",
      "\n",
      "2023-08-15 21:49:32,328 - ERROR - Error at method fetch_and_store_data : not enough values to unpack (expected 2, got 0)\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\eyawo\\anaconda3\\lib\\site-packages\\twitter_scraper_selenium\\keyword.py\", line 73, in fetch_and_store_data\n",
      "    status, tweet_url = Finder.find_status(tweet)\n",
      "ValueError: not enough values to unpack (expected 2, got 0)\n"
     ]
    }
   ],
   "source": [
    "from twitter_scraper_selenium import scrape_keyword\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Scrape tweets\n",
    "tweets_count = 50\n",
    "tweets = []\n",
    "\n",
    "while len(tweets) < tweets_count:\n",
    "    # Scrape tweets in batches of 10\n",
    "    batch_tweets = scrape_keyword(\n",
    "        keyword=\"#news\",\n",
    "        browser=\"firefox\",\n",
    "        tweets_count=10,\n",
    "        headless=False\n",
    "    )\n",
    "    \n",
    "    # Filter out duplicate tweets\n",
    "    new_tweets = [tweet for tweet in batch_tweets if tweet not in tweets]\n",
    "    \n",
    "    # Add new tweets to the list\n",
    "    tweets.extend(new_tweets)\n",
    "    \n",
    "    # Scroll down to load more tweets\n",
    "    if len(tweets) < tweets_count:\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(5)  # Allow time for tweets to load\n",
    "\n",
    "# Create a DataFrame with a single column named \"Tweets\"\n",
    "df = pd.DataFrame(tweets, columns=[\"Tweets\"])\n",
    "\n",
    "# Save DataFrame to a CSV file\n",
    "filename = \"news2_tweets.csv\"\n",
    "df.to_csv(filename, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "0a6ecaba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - Driver [C:\\Users\\eyawo\\.wdm\\drivers\\geckodriver\\win64\\v0.33.0\\geckodriver.exe] found in cache\n",
      "2023-08-15 22:48:46,905 - twitter_scraper_selenium.element_finder - ERROR - Error at method find_status : Message: Unable to locate element: a[aria-label][dir]\n",
      "Stacktrace:\n",
      "RemoteError@chrome://remote/content/shared/RemoteError.sys.mjs:8:8\n",
      "WebDriverError@chrome://remote/content/shared/webdriver/Errors.sys.mjs:187:5\n",
      "NoSuchElementError@chrome://remote/content/shared/webdriver/Errors.sys.mjs:505:5\n",
      "dom.find/</<@chrome://remote/content/shared/DOM.sys.mjs:132:16\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\eyawo\\anaconda3\\lib\\site-packages\\twitter_scraper_selenium\\element_finder.py\", line 68, in find_status\n",
      "    anchor = tweet.find_element(\n",
      "  File \"C:\\Users\\eyawo\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py\", line 433, in find_element\n",
      "    return self._execute(Command.FIND_CHILD_ELEMENT, {\"using\": by, \"value\": value})[\"value\"]\n",
      "  File \"C:\\Users\\eyawo\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py\", line 410, in _execute\n",
      "    return self._parent.execute(command, params)\n",
      "  File \"C:\\Users\\eyawo\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\", line 444, in execute\n",
      "    self.error_handler.check_response(response)\n",
      "  File \"C:\\Users\\eyawo\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\", line 249, in check_response\n",
      "    raise exception_class(message, screen, stacktrace)\n",
      "selenium.common.exceptions.NoSuchElementException: Message: Unable to locate element: a[aria-label][dir]\n",
      "Stacktrace:\n",
      "RemoteError@chrome://remote/content/shared/RemoteError.sys.mjs:8:8\n",
      "WebDriverError@chrome://remote/content/shared/webdriver/Errors.sys.mjs:187:5\n",
      "NoSuchElementError@chrome://remote/content/shared/webdriver/Errors.sys.mjs:505:5\n",
      "dom.find/</<@chrome://remote/content/shared/DOM.sys.mjs:132:16\n",
      "\n",
      "2023-08-15 22:48:46,909 - ERROR - Error at method fetch_and_store_data : not enough values to unpack (expected 2, got 0)\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\eyawo\\anaconda3\\lib\\site-packages\\twitter_scraper_selenium\\keyword.py\", line 73, in fetch_and_store_data\n",
      "    status, tweet_url = Finder.find_status(tweet)\n",
      "ValueError: not enough values to unpack (expected 2, got 0)\n"
     ]
    }
   ],
   "source": [
    "from twitter_scraper_selenium import scrape_keyword\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Scrape tweets\n",
    "tweets_count = 50\n",
    "tweets = []\n",
    "\n",
    "while len(tweets) < tweets_count:\n",
    "    # Scrape tweets in batches of 10\n",
    "    batch_tweets = scrape_keyword(\n",
    "        keyword=\"#news\",\n",
    "        browser=\"firefox\",\n",
    "        tweets_count=10,\n",
    "        headless=False\n",
    "    )\n",
    "    \n",
    "    # Filter out duplicate tweets\n",
    "    new_tweets = [tweet for tweet in batch_tweets if tweet not in tweets]\n",
    "    \n",
    "    # Add new tweets to the list\n",
    "    tweets.extend(new_tweets)\n",
    "    \n",
    "    # Scroll down to load more tweets\n",
    "    if len(tweets) < tweets_count:\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(5)  # Allow time for tweets to load\n",
    "\n",
    "# Create a DataFrame with a single column named \"Tweets\"\n",
    "df = pd.DataFrame(tweets, columns=[\"Tweets\"])\n",
    "\n",
    "# Save DataFrame to a CSV file\n",
    "filename = \"ntxt.csv\"\n",
    "df.to_csv(filename, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "016be416",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('ntxt.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "74d02f9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1482</th>\n",
       "      <td>:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1483</th>\n",
       "      <td>\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1484</th>\n",
       "      <td>\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1485</th>\n",
       "      <td>}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1486</th>\n",
       "      <td>}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1487 rows  1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Tweets\n",
       "0         {\n",
       "1         \"\n",
       "2         1\n",
       "3         6\n",
       "4         9\n",
       "...     ...\n",
       "1482      :\n",
       "1483      \"\n",
       "1484      \"\n",
       "1485      }\n",
       "1486      }\n",
       "\n",
       "[1487 rows x 1 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347667df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
